{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 10 â€“ Introduction to Artificial Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercices in chapter 10._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "rnd.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure perceptron_iris_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAEYCAYAAABBfQDEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe600f9d0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap, linewidth=5)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "save_fig(\"perceptron_iris_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure activation_functions_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAEYCAYAAADMNRC5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCGEcJpkIIQQQgghhBBO+3+UD372ebgo/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5fea87050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(z, logit(z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(logit, z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "#plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Derivatives\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"activation_functions_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heaviside(z):\n",
    "    return (z >= 0).astype(z.dtype)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def mlp_xor(x1, x2, activation=heaviside):\n",
    "    return activation(-activation(x1 + x2 - 1.5) + activation(x1 + x2 - 0.5) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAEMCAYAAACfoCGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npImIiIgUkEKaiIiISAEppImIiIgU0P8Hut8DXs9ag3AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5feae5ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1s = np.linspace(-0.2, 1.2, 100)\n",
    "x2s = np.linspace(-0.2, 1.2, 100)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "z1 = mlp_xor(x1, x2, activation=heaviside)\n",
    "z2 = mlp_xor(x1, x2, activation=sigmoid)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.contourf(x1, x2, z1)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: heaviside\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.contourf(x1, x2, z2)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: sigmoid\", fontsize=14)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNN for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using tf.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': None, '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe5f5f5f650>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp5IuIZf\n",
      "WARNING:tensorflow:From <ipython-input-10-dbff31ba643f>:6: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-10-dbff31ba643f>:6: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-10-dbff31ba643f>:6: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py:248: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp5IuIZf/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.34488, step = 1\n",
      "INFO:tensorflow:global_step/sec: 255.505\n",
      "INFO:tensorflow:loss = 0.323739, step = 101 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.044\n",
      "INFO:tensorflow:loss = 0.281535, step = 201 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.56\n",
      "INFO:tensorflow:loss = 0.406025, step = 301 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.924\n",
      "INFO:tensorflow:loss = 0.249963, step = 401 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.481\n",
      "INFO:tensorflow:loss = 0.248108, step = 501 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.564\n",
      "INFO:tensorflow:loss = 0.0593232, step = 601 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.479\n",
      "INFO:tensorflow:loss = 0.151743, step = 701 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.179\n",
      "INFO:tensorflow:loss = 0.197613, step = 801 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.502\n",
      "INFO:tensorflow:loss = 0.108102, step = 901 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.203\n",
      "INFO:tensorflow:loss = 0.233006, step = 1001 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.824\n",
      "INFO:tensorflow:loss = 0.177675, step = 1101 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.486\n",
      "INFO:tensorflow:loss = 0.11412, step = 1201 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.704\n",
      "INFO:tensorflow:loss = 0.189655, step = 1301 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.358\n",
      "INFO:tensorflow:loss = 0.0820443, step = 1401 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.665\n",
      "INFO:tensorflow:loss = 0.0982187, step = 1501 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.025\n",
      "INFO:tensorflow:loss = 0.133424, step = 1601 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.849\n",
      "INFO:tensorflow:loss = 0.0340255, step = 1701 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.018\n",
      "INFO:tensorflow:loss = 0.149374, step = 1801 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.931\n",
      "INFO:tensorflow:loss = 0.0745866, step = 1901 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.87\n",
      "INFO:tensorflow:loss = 0.0733413, step = 2001 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.89\n",
      "INFO:tensorflow:loss = 0.0171984, step = 2101 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.584\n",
      "INFO:tensorflow:loss = 0.0430207, step = 2201 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.919\n",
      "INFO:tensorflow:loss = 0.0672145, step = 2301 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.797\n",
      "INFO:tensorflow:loss = 0.0368781, step = 2401 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.057\n",
      "INFO:tensorflow:loss = 0.0420911, step = 2501 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.077\n",
      "INFO:tensorflow:loss = 0.0350752, step = 2601 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.972\n",
      "INFO:tensorflow:loss = 0.0158256, step = 2701 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.176\n",
      "INFO:tensorflow:loss = 0.0523733, step = 2801 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.843\n",
      "INFO:tensorflow:loss = 0.121708, step = 2901 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.954\n",
      "INFO:tensorflow:loss = 0.0208197, step = 3001 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.096\n",
      "INFO:tensorflow:loss = 0.0625649, step = 3101 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.198\n",
      "INFO:tensorflow:loss = 0.0162045, step = 3201 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.941\n",
      "INFO:tensorflow:loss = 0.0206434, step = 3301 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.134\n",
      "INFO:tensorflow:loss = 0.167891, step = 3401 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.973\n",
      "INFO:tensorflow:loss = 0.0599268, step = 3501 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.696\n",
      "INFO:tensorflow:loss = 0.156972, step = 3601 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.5\n",
      "INFO:tensorflow:loss = 0.055407, step = 3701 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.305\n",
      "INFO:tensorflow:loss = 0.0137275, step = 3801 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.453\n",
      "INFO:tensorflow:loss = 0.113925, step = 3901 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.472\n",
      "INFO:tensorflow:loss = 0.158324, step = 4001 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.958\n",
      "INFO:tensorflow:loss = 0.0198171, step = 4101 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.918\n",
      "INFO:tensorflow:loss = 0.0653953, step = 4201 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.159\n",
      "INFO:tensorflow:loss = 0.184541, step = 4301 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.82\n",
      "INFO:tensorflow:loss = 0.148998, step = 4401 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.68\n",
      "INFO:tensorflow:loss = 0.0157654, step = 4501 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.52\n",
      "INFO:tensorflow:loss = 0.0341876, step = 4601 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.263\n",
      "INFO:tensorflow:loss = 0.00829835, step = 4701 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.062\n",
      "INFO:tensorflow:loss = 0.0219496, step = 4801 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.224\n",
      "INFO:tensorflow:loss = 0.0493354, step = 4901 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.817\n",
      "INFO:tensorflow:loss = 0.0611185, step = 5001 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.829\n",
      "INFO:tensorflow:loss = 0.0078249, step = 5101 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.466\n",
      "INFO:tensorflow:loss = 0.0278978, step = 5201 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.661\n",
      "INFO:tensorflow:loss = 0.0439769, step = 5301 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.217\n",
      "INFO:tensorflow:loss = 0.079016, step = 5401 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.737\n",
      "INFO:tensorflow:loss = 0.0483976, step = 5501 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.791\n",
      "INFO:tensorflow:loss = 0.0582259, step = 5601 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.588\n",
      "INFO:tensorflow:loss = 0.0132976, step = 5701 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.335\n",
      "INFO:tensorflow:loss = 0.00849449, step = 5801 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.343\n",
      "INFO:tensorflow:loss = 0.041529, step = 5901 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.477\n",
      "INFO:tensorflow:loss = 0.147797, step = 6001 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.542\n",
      "INFO:tensorflow:loss = 0.0173173, step = 6101 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.007\n",
      "INFO:tensorflow:loss = 0.0122336, step = 6201 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.986\n",
      "INFO:tensorflow:loss = 0.0651713, step = 6301 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.224\n",
      "INFO:tensorflow:loss = 0.0327383, step = 6401 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.479\n",
      "INFO:tensorflow:loss = 0.019667, step = 6501 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.574\n",
      "INFO:tensorflow:loss = 0.00738333, step = 6601 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.42\n",
      "INFO:tensorflow:loss = 0.0159331, step = 6701 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.137\n",
      "INFO:tensorflow:loss = 0.00797644, step = 6801 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.899\n",
      "INFO:tensorflow:loss = 0.0124018, step = 6901 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.437\n",
      "INFO:tensorflow:loss = 0.0220557, step = 7001 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.03\n",
      "INFO:tensorflow:loss = 0.00576423, step = 7101 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.822\n",
      "INFO:tensorflow:loss = 0.0842737, step = 7201 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.174\n",
      "INFO:tensorflow:loss = 0.0107172, step = 7301 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.643\n",
      "INFO:tensorflow:loss = 0.0233572, step = 7401 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.351\n",
      "INFO:tensorflow:loss = 0.00422944, step = 7501 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.927\n",
      "INFO:tensorflow:loss = 0.0206646, step = 7601 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.613\n",
      "INFO:tensorflow:loss = 0.0135299, step = 7701 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.576\n",
      "INFO:tensorflow:loss = 0.00476464, step = 7801 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.848\n",
      "INFO:tensorflow:loss = 0.00582082, step = 7901 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.208\n",
      "INFO:tensorflow:loss = 0.0019252, step = 8001 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.635\n",
      "INFO:tensorflow:loss = 0.00857155, step = 8101 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.44\n",
      "INFO:tensorflow:loss = 0.0235456, step = 8201 (0.406 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 229.011\n",
      "INFO:tensorflow:loss = 0.0428183, step = 8301 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.978\n",
      "INFO:tensorflow:loss = 0.00371833, step = 8401 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.061\n",
      "INFO:tensorflow:loss = 0.00668231, step = 8501 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.674\n",
      "INFO:tensorflow:loss = 0.00293888, step = 8601 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.669\n",
      "INFO:tensorflow:loss = 0.00246011, step = 8701 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.551\n",
      "INFO:tensorflow:loss = 0.012253, step = 8801 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.733\n",
      "INFO:tensorflow:loss = 0.00317227, step = 8901 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.185\n",
      "INFO:tensorflow:loss = 0.00890412, step = 9001 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.006\n",
      "INFO:tensorflow:loss = 0.00552503, step = 9101 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.3\n",
      "INFO:tensorflow:loss = 0.00374534, step = 9201 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.897\n",
      "INFO:tensorflow:loss = 0.00894351, step = 9301 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.392\n",
      "INFO:tensorflow:loss = 0.0301419, step = 9401 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.125\n",
      "INFO:tensorflow:loss = 0.00603698, step = 9501 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.954\n",
      "INFO:tensorflow:loss = 0.0353396, step = 9601 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.756\n",
      "INFO:tensorflow:loss = 0.00980354, step = 9701 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.814\n",
      "INFO:tensorflow:loss = 0.00139107, step = 9801 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.415\n",
      "INFO:tensorflow:loss = 0.0165013, step = 9901 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.482\n",
      "INFO:tensorflow:loss = 0.00504377, step = 10001 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.593\n",
      "INFO:tensorflow:loss = 0.00895708, step = 10101 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.692\n",
      "INFO:tensorflow:loss = 0.0128135, step = 10201 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.577\n",
      "INFO:tensorflow:loss = 0.00278856, step = 10301 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.138\n",
      "INFO:tensorflow:loss = 0.0118289, step = 10401 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.491\n",
      "INFO:tensorflow:loss = 0.00543451, step = 10501 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.491\n",
      "INFO:tensorflow:loss = 0.0356666, step = 10601 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.906\n",
      "INFO:tensorflow:loss = 0.0369289, step = 10701 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.796\n",
      "INFO:tensorflow:loss = 0.00228704, step = 10801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.898\n",
      "INFO:tensorflow:loss = 0.0011733, step = 10901 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.93\n",
      "INFO:tensorflow:loss = 0.0345945, step = 11001 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.242\n",
      "INFO:tensorflow:loss = 0.00541247, step = 11101 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.8\n",
      "INFO:tensorflow:loss = 0.00096823, step = 11201 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.337\n",
      "INFO:tensorflow:loss = 0.00596178, step = 11301 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.704\n",
      "INFO:tensorflow:loss = 0.00751445, step = 11401 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.645\n",
      "INFO:tensorflow:loss = 0.0132837, step = 11501 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.75\n",
      "INFO:tensorflow:loss = 0.000574598, step = 11601 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.528\n",
      "INFO:tensorflow:loss = 0.00265658, step = 11701 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.075\n",
      "INFO:tensorflow:loss = 0.000317562, step = 11801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.557\n",
      "INFO:tensorflow:loss = 0.00864884, step = 11901 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.192\n",
      "INFO:tensorflow:loss = 0.000274775, step = 12001 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.34\n",
      "INFO:tensorflow:loss = 0.00252922, step = 12101 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.013\n",
      "INFO:tensorflow:loss = 0.00458476, step = 12201 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.531\n",
      "INFO:tensorflow:loss = 0.00822269, step = 12301 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.584\n",
      "INFO:tensorflow:loss = 0.000420007, step = 12401 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.649\n",
      "INFO:tensorflow:loss = 0.00247987, step = 12501 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.055\n",
      "INFO:tensorflow:loss = 0.00234326, step = 12601 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.026\n",
      "INFO:tensorflow:loss = 0.00250877, step = 12701 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.521\n",
      "INFO:tensorflow:loss = 0.0110152, step = 12801 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.095\n",
      "INFO:tensorflow:loss = 0.0039043, step = 12901 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.179\n",
      "INFO:tensorflow:loss = 0.00435367, step = 13001 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.635\n",
      "INFO:tensorflow:loss = 0.00319459, step = 13101 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.721\n",
      "INFO:tensorflow:loss = 0.00394852, step = 13201 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.705\n",
      "INFO:tensorflow:loss = 0.00479438, step = 13301 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.418\n",
      "INFO:tensorflow:loss = 0.00605201, step = 13401 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.808\n",
      "INFO:tensorflow:loss = 0.0133047, step = 13501 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.59\n",
      "INFO:tensorflow:loss = 0.00314102, step = 13601 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.226\n",
      "INFO:tensorflow:loss = 0.00179148, step = 13701 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.99\n",
      "INFO:tensorflow:loss = 0.0057193, step = 13801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.746\n",
      "INFO:tensorflow:loss = 0.00359851, step = 13901 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.318\n",
      "INFO:tensorflow:loss = 0.0016952, step = 14001 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.448\n",
      "INFO:tensorflow:loss = 0.00785485, step = 14101 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.269\n",
      "INFO:tensorflow:loss = 0.00552828, step = 14201 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.388\n",
      "INFO:tensorflow:loss = 0.00165316, step = 14301 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.795\n",
      "INFO:tensorflow:loss = 0.00036223, step = 14401 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.446\n",
      "INFO:tensorflow:loss = 0.000637177, step = 14501 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.671\n",
      "INFO:tensorflow:loss = 0.00308722, step = 14601 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.532\n",
      "INFO:tensorflow:loss = 0.00290062, step = 14701 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.816\n",
      "INFO:tensorflow:loss = 0.000661621, step = 14801 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.273\n",
      "INFO:tensorflow:loss = 0.0026268, step = 14901 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.884\n",
      "INFO:tensorflow:loss = 0.00129747, step = 15001 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.965\n",
      "INFO:tensorflow:loss = 0.002278, step = 15101 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.202\n",
      "INFO:tensorflow:loss = 0.00159828, step = 15201 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.027\n",
      "INFO:tensorflow:loss = 0.00342165, step = 15301 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.71\n",
      "INFO:tensorflow:loss = 0.00266609, step = 15401 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.041\n",
      "INFO:tensorflow:loss = 0.00790891, step = 15501 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.949\n",
      "INFO:tensorflow:loss = 0.00439692, step = 15601 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.996\n",
      "INFO:tensorflow:loss = 0.0117072, step = 15701 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.239\n",
      "INFO:tensorflow:loss = 0.000963109, step = 15801 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.975\n",
      "INFO:tensorflow:loss = 0.000327877, step = 15901 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.177\n",
      "INFO:tensorflow:loss = 0.004732, step = 16001 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.014\n",
      "INFO:tensorflow:loss = 0.00211001, step = 16101 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.576\n",
      "INFO:tensorflow:loss = 0.000188449, step = 16201 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.572\n",
      "INFO:tensorflow:loss = 0.00401309, step = 16301 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.958\n",
      "INFO:tensorflow:loss = 0.00175906, step = 16401 (0.368 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 258.388\n",
      "INFO:tensorflow:loss = 0.0020856, step = 16501 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.58\n",
      "INFO:tensorflow:loss = 0.00286917, step = 16601 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.244\n",
      "INFO:tensorflow:loss = 0.00196519, step = 16701 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.959\n",
      "INFO:tensorflow:loss = 0.00233599, step = 16801 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.158\n",
      "INFO:tensorflow:loss = 0.00309921, step = 16901 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.398\n",
      "INFO:tensorflow:loss = 0.0068281, step = 17001 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.748\n",
      "INFO:tensorflow:loss = 0.00188883, step = 17101 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.288\n",
      "INFO:tensorflow:loss = 0.00303493, step = 17201 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.792\n",
      "INFO:tensorflow:loss = 0.00116679, step = 17301 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.365\n",
      "INFO:tensorflow:loss = 0.00180978, step = 17401 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.885\n",
      "INFO:tensorflow:loss = 0.00131416, step = 17501 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.875\n",
      "INFO:tensorflow:loss = 0.000401793, step = 17601 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.946\n",
      "INFO:tensorflow:loss = 0.000638253, step = 17701 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.71\n",
      "INFO:tensorflow:loss = 0.00049935, step = 17801 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.129\n",
      "INFO:tensorflow:loss = 0.00270411, step = 17901 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.574\n",
      "INFO:tensorflow:loss = 0.000246878, step = 18001 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.346\n",
      "INFO:tensorflow:loss = 0.000838657, step = 18101 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.371\n",
      "INFO:tensorflow:loss = 0.00703309, step = 18201 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.447\n",
      "INFO:tensorflow:loss = 0.0134659, step = 18301 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.939\n",
      "INFO:tensorflow:loss = 0.00297388, step = 18401 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.563\n",
      "INFO:tensorflow:loss = 0.00060423, step = 18501 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.896\n",
      "INFO:tensorflow:loss = 0.00299747, step = 18601 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.274\n",
      "INFO:tensorflow:loss = 0.00114772, step = 18701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.395\n",
      "INFO:tensorflow:loss = 0.00224915, step = 18801 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.634\n",
      "INFO:tensorflow:loss = 0.00268369, step = 18901 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.461\n",
      "INFO:tensorflow:loss = 0.00113727, step = 19001 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.122\n",
      "INFO:tensorflow:loss = 0.000515031, step = 19101 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.147\n",
      "INFO:tensorflow:loss = 0.000655745, step = 19201 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.042\n",
      "INFO:tensorflow:loss = 0.00512455, step = 19301 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.873\n",
      "INFO:tensorflow:loss = 0.000395694, step = 19401 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.62\n",
      "INFO:tensorflow:loss = 0.00167934, step = 19501 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.124\n",
      "INFO:tensorflow:loss = 0.000299657, step = 19601 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.895\n",
      "INFO:tensorflow:loss = 0.00013579, step = 19701 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.986\n",
      "INFO:tensorflow:loss = 0.000681374, step = 19801 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.608\n",
      "INFO:tensorflow:loss = 0.0019307, step = 19901 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.008\n",
      "INFO:tensorflow:loss = 0.00314294, step = 20001 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.689\n",
      "INFO:tensorflow:loss = 0.000522799, step = 20101 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.853\n",
      "INFO:tensorflow:loss = 0.00291746, step = 20201 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.063\n",
      "INFO:tensorflow:loss = 0.0021572, step = 20301 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.882\n",
      "INFO:tensorflow:loss = 0.000162243, step = 20401 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.144\n",
      "INFO:tensorflow:loss = 0.00113898, step = 20501 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.597\n",
      "INFO:tensorflow:loss = 0.00113292, step = 20601 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.866\n",
      "INFO:tensorflow:loss = 0.000968894, step = 20701 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.255\n",
      "INFO:tensorflow:loss = 0.000882549, step = 20801 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.911\n",
      "INFO:tensorflow:loss = 0.000786176, step = 20901 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.508\n",
      "INFO:tensorflow:loss = 0.00109579, step = 21001 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.614\n",
      "INFO:tensorflow:loss = 0.00126909, step = 21101 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.179\n",
      "INFO:tensorflow:loss = 0.00447801, step = 21201 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.66\n",
      "INFO:tensorflow:loss = 0.00107064, step = 21301 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.038\n",
      "INFO:tensorflow:loss = 0.00210688, step = 21401 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.894\n",
      "INFO:tensorflow:loss = 0.000199241, step = 21501 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.929\n",
      "INFO:tensorflow:loss = 0.0010071, step = 21601 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.973\n",
      "INFO:tensorflow:loss = 0.00101014, step = 21701 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.065\n",
      "INFO:tensorflow:loss = 0.000429206, step = 21801 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.704\n",
      "INFO:tensorflow:loss = 0.000581485, step = 21901 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.888\n",
      "INFO:tensorflow:loss = 0.000190937, step = 22001 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.156\n",
      "INFO:tensorflow:loss = 0.000162428, step = 22101 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.916\n",
      "INFO:tensorflow:loss = 0.00135611, step = 22201 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.229\n",
      "INFO:tensorflow:loss = 0.00225756, step = 22301 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.343\n",
      "INFO:tensorflow:loss = 0.00263384, step = 22401 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.305\n",
      "INFO:tensorflow:loss = 0.00113173, step = 22501 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.492\n",
      "INFO:tensorflow:loss = 0.00224202, step = 22601 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.933\n",
      "INFO:tensorflow:loss = 0.00071299, step = 22701 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.607\n",
      "INFO:tensorflow:loss = 0.000817863, step = 22801 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.375\n",
      "INFO:tensorflow:loss = 0.00183483, step = 22901 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.587\n",
      "INFO:tensorflow:loss = 0.000528808, step = 23001 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.147\n",
      "INFO:tensorflow:loss = 0.00352407, step = 23101 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.805\n",
      "INFO:tensorflow:loss = 0.00247679, step = 23201 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.352\n",
      "INFO:tensorflow:loss = 0.00181819, step = 23301 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.05\n",
      "INFO:tensorflow:loss = 0.000370494, step = 23401 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.019\n",
      "INFO:tensorflow:loss = 0.000738692, step = 23501 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.535\n",
      "INFO:tensorflow:loss = 0.000509968, step = 23601 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.146\n",
      "INFO:tensorflow:loss = 0.000409448, step = 23701 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.389\n",
      "INFO:tensorflow:loss = 0.00108484, step = 23801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.638\n",
      "INFO:tensorflow:loss = 0.0021965, step = 23901 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.655\n",
      "INFO:tensorflow:loss = 0.000771881, step = 24001 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.152\n",
      "INFO:tensorflow:loss = 0.000475506, step = 24101 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.098\n",
      "INFO:tensorflow:loss = 0.00193424, step = 24201 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.292\n",
      "INFO:tensorflow:loss = 0.000132956, step = 24301 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.111\n",
      "INFO:tensorflow:loss = 0.00219732, step = 24401 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.698\n",
      "INFO:tensorflow:loss = 0.000680545, step = 24501 (0.354 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 270.928\n",
      "INFO:tensorflow:loss = 0.000524579, step = 24601 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.857\n",
      "INFO:tensorflow:loss = 0.000702553, step = 24701 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.176\n",
      "INFO:tensorflow:loss = 0.00118266, step = 24801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.343\n",
      "INFO:tensorflow:loss = 0.00156498, step = 24901 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.721\n",
      "INFO:tensorflow:loss = 0.000324346, step = 25001 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.233\n",
      "INFO:tensorflow:loss = 0.000636639, step = 25101 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.971\n",
      "INFO:tensorflow:loss = 0.00158891, step = 25201 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.13\n",
      "INFO:tensorflow:loss = 0.000225484, step = 25301 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.353\n",
      "INFO:tensorflow:loss = 0.000618174, step = 25401 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.563\n",
      "INFO:tensorflow:loss = 0.000704226, step = 25501 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.319\n",
      "INFO:tensorflow:loss = 0.00116179, step = 25601 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.146\n",
      "INFO:tensorflow:loss = 0.000560809, step = 25701 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.758\n",
      "INFO:tensorflow:loss = 0.00088587, step = 25801 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.283\n",
      "INFO:tensorflow:loss = 0.00146836, step = 25901 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.229\n",
      "INFO:tensorflow:loss = 0.000101177, step = 26001 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.821\n",
      "INFO:tensorflow:loss = 0.0010745, step = 26101 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.412\n",
      "INFO:tensorflow:loss = 0.000931381, step = 26201 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.825\n",
      "INFO:tensorflow:loss = 0.000859518, step = 26301 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.907\n",
      "INFO:tensorflow:loss = 0.00166818, step = 26401 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.247\n",
      "INFO:tensorflow:loss = 0.000905287, step = 26501 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.394\n",
      "INFO:tensorflow:loss = 0.000454095, step = 26601 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.114\n",
      "INFO:tensorflow:loss = 1.24006e-05, step = 26701 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.069\n",
      "INFO:tensorflow:loss = 0.0006008, step = 26801 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.301\n",
      "INFO:tensorflow:loss = 0.000902614, step = 26901 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.622\n",
      "INFO:tensorflow:loss = 0.000741644, step = 27001 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.187\n",
      "INFO:tensorflow:loss = 0.000601308, step = 27101 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.191\n",
      "INFO:tensorflow:loss = 0.000353492, step = 27201 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.229\n",
      "INFO:tensorflow:loss = 0.00110245, step = 27301 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.535\n",
      "INFO:tensorflow:loss = 0.000100508, step = 27401 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.135\n",
      "INFO:tensorflow:loss = 0.00129328, step = 27501 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.905\n",
      "INFO:tensorflow:loss = 0.00112368, step = 27601 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.265\n",
      "INFO:tensorflow:loss = 0.000239844, step = 27701 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.342\n",
      "INFO:tensorflow:loss = 0.000427323, step = 27801 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.709\n",
      "INFO:tensorflow:loss = 0.000667409, step = 27901 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.666\n",
      "INFO:tensorflow:loss = 0.0012053, step = 28001 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.241\n",
      "INFO:tensorflow:loss = 0.000563359, step = 28101 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.504\n",
      "INFO:tensorflow:loss = 0.000719393, step = 28201 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.073\n",
      "INFO:tensorflow:loss = 0.000788454, step = 28301 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.177\n",
      "INFO:tensorflow:loss = 0.000825252, step = 28401 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.301\n",
      "INFO:tensorflow:loss = 0.000287847, step = 28501 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.455\n",
      "INFO:tensorflow:loss = 0.000345623, step = 28601 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.951\n",
      "INFO:tensorflow:loss = 0.00105283, step = 28701 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.978\n",
      "INFO:tensorflow:loss = 0.00104335, step = 28801 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.564\n",
      "INFO:tensorflow:loss = 0.000268877, step = 28901 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.937\n",
      "INFO:tensorflow:loss = 0.00170347, step = 29001 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.763\n",
      "INFO:tensorflow:loss = 0.00147094, step = 29101 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.746\n",
      "INFO:tensorflow:loss = 0.00162526, step = 29201 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.493\n",
      "INFO:tensorflow:loss = 0.00147524, step = 29301 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.438\n",
      "INFO:tensorflow:loss = 0.000763675, step = 29401 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.373\n",
      "INFO:tensorflow:loss = 0.00133546, step = 29501 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.314\n",
      "INFO:tensorflow:loss = 0.00024006, step = 29601 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.938\n",
      "INFO:tensorflow:loss = 0.000426923, step = 29701 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.415\n",
      "INFO:tensorflow:loss = 0.000501532, step = 29801 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.171\n",
      "INFO:tensorflow:loss = 0.00135496, step = 29901 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.762\n",
      "INFO:tensorflow:loss = 4.38351e-05, step = 30001 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.58\n",
      "INFO:tensorflow:loss = 0.00047037, step = 30101 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.575\n",
      "INFO:tensorflow:loss = 0.000336653, step = 30201 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.566\n",
      "INFO:tensorflow:loss = 0.00118518, step = 30301 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.992\n",
      "INFO:tensorflow:loss = 0.00177536, step = 30401 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.98\n",
      "INFO:tensorflow:loss = 0.000871805, step = 30501 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.499\n",
      "INFO:tensorflow:loss = 0.000695326, step = 30601 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.257\n",
      "INFO:tensorflow:loss = 0.0006382, step = 30701 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.452\n",
      "INFO:tensorflow:loss = 0.00111644, step = 30801 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.549\n",
      "INFO:tensorflow:loss = 0.00139715, step = 30901 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.238\n",
      "INFO:tensorflow:loss = 0.00135389, step = 31001 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.698\n",
      "INFO:tensorflow:loss = 0.00115907, step = 31101 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.927\n",
      "INFO:tensorflow:loss = 0.000333259, step = 31201 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.789\n",
      "INFO:tensorflow:loss = 0.000754338, step = 31301 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.591\n",
      "INFO:tensorflow:loss = 0.000960068, step = 31401 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.98\n",
      "INFO:tensorflow:loss = 0.00039818, step = 31501 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.646\n",
      "INFO:tensorflow:loss = 0.000227982, step = 31601 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.635\n",
      "INFO:tensorflow:loss = 0.000776001, step = 31701 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.904\n",
      "INFO:tensorflow:loss = 0.000246862, step = 31801 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.816\n",
      "INFO:tensorflow:loss = 0.000757172, step = 31901 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.052\n",
      "INFO:tensorflow:loss = 0.000317389, step = 32001 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.669\n",
      "INFO:tensorflow:loss = 0.000304677, step = 32101 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.139\n",
      "INFO:tensorflow:loss = 0.00130583, step = 32201 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.974\n",
      "INFO:tensorflow:loss = 0.000526704, step = 32301 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.406\n",
      "INFO:tensorflow:loss = 0.000117633, step = 32401 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.209\n",
      "INFO:tensorflow:loss = 0.000650911, step = 32501 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.218\n",
      "INFO:tensorflow:loss = 0.000165107, step = 32601 (0.357 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 273.105\n",
      "INFO:tensorflow:loss = 0.0010359, step = 32701 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.686\n",
      "INFO:tensorflow:loss = 0.00122532, step = 32801 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.251\n",
      "INFO:tensorflow:loss = 0.000368626, step = 32901 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.294\n",
      "INFO:tensorflow:loss = 0.00044226, step = 33001 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.768\n",
      "INFO:tensorflow:loss = 0.00164005, step = 33101 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.362\n",
      "INFO:tensorflow:loss = 0.000592054, step = 33201 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.577\n",
      "INFO:tensorflow:loss = 0.000233776, step = 33301 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.521\n",
      "INFO:tensorflow:loss = 0.000980824, step = 33401 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.945\n",
      "INFO:tensorflow:loss = 0.000279776, step = 33501 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.444\n",
      "INFO:tensorflow:loss = 0.000427851, step = 33601 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.516\n",
      "INFO:tensorflow:loss = 0.000880914, step = 33701 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.921\n",
      "INFO:tensorflow:loss = 0.0011821, step = 33801 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.87\n",
      "INFO:tensorflow:loss = 0.00111672, step = 33901 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.197\n",
      "INFO:tensorflow:loss = 0.000833355, step = 34001 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.828\n",
      "INFO:tensorflow:loss = 0.000580541, step = 34101 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.675\n",
      "INFO:tensorflow:loss = 0.00157088, step = 34201 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.337\n",
      "INFO:tensorflow:loss = 8.5633e-05, step = 34301 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.908\n",
      "INFO:tensorflow:loss = 0.000711614, step = 34401 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.76\n",
      "INFO:tensorflow:loss = 0.00059396, step = 34501 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.221\n",
      "INFO:tensorflow:loss = 0.000232589, step = 34601 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.619\n",
      "INFO:tensorflow:loss = 0.00144423, step = 34701 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.516\n",
      "INFO:tensorflow:loss = 0.000579184, step = 34801 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.926\n",
      "INFO:tensorflow:loss = 0.000523038, step = 34901 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.397\n",
      "INFO:tensorflow:loss = 0.000507069, step = 35001 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.995\n",
      "INFO:tensorflow:loss = 0.000545827, step = 35101 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.862\n",
      "INFO:tensorflow:loss = 0.000237571, step = 35201 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.199\n",
      "INFO:tensorflow:loss = 0.000300063, step = 35301 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.61\n",
      "INFO:tensorflow:loss = 0.000984687, step = 35401 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.039\n",
      "INFO:tensorflow:loss = 0.000238735, step = 35501 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.009\n",
      "INFO:tensorflow:loss = 0.000277545, step = 35601 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.238\n",
      "INFO:tensorflow:loss = 0.000759224, step = 35701 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.506\n",
      "INFO:tensorflow:loss = 0.000667959, step = 35801 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.921\n",
      "INFO:tensorflow:loss = 0.000583766, step = 35901 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.896\n",
      "INFO:tensorflow:loss = 0.00036604, step = 36001 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.913\n",
      "INFO:tensorflow:loss = 0.00101818, step = 36101 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.314\n",
      "INFO:tensorflow:loss = 0.000672441, step = 36201 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.49\n",
      "INFO:tensorflow:loss = 0.000328343, step = 36301 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.883\n",
      "INFO:tensorflow:loss = 0.000954318, step = 36401 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.786\n",
      "INFO:tensorflow:loss = 0.000428975, step = 36501 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.965\n",
      "INFO:tensorflow:loss = 0.000390562, step = 36601 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.617\n",
      "INFO:tensorflow:loss = 0.00032881, step = 36701 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.747\n",
      "INFO:tensorflow:loss = 0.000761337, step = 36801 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.765\n",
      "INFO:tensorflow:loss = 0.000621777, step = 36901 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.445\n",
      "INFO:tensorflow:loss = 0.000825301, step = 37001 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.723\n",
      "INFO:tensorflow:loss = 0.000216818, step = 37101 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.271\n",
      "INFO:tensorflow:loss = 0.000286201, step = 37201 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.542\n",
      "INFO:tensorflow:loss = 0.000643232, step = 37301 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.39\n",
      "INFO:tensorflow:loss = 0.000384767, step = 37401 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.819\n",
      "INFO:tensorflow:loss = 0.00033816, step = 37501 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.317\n",
      "INFO:tensorflow:loss = 0.000402807, step = 37601 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.471\n",
      "INFO:tensorflow:loss = 7.94202e-05, step = 37701 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.984\n",
      "INFO:tensorflow:loss = 0.000270085, step = 37801 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.354\n",
      "INFO:tensorflow:loss = 0.00173004, step = 37901 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.546\n",
      "INFO:tensorflow:loss = 0.000159321, step = 38001 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.426\n",
      "INFO:tensorflow:loss = 0.000750703, step = 38101 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.945\n",
      "INFO:tensorflow:loss = 0.000750325, step = 38201 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.151\n",
      "INFO:tensorflow:loss = 7.06733e-05, step = 38301 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.615\n",
      "INFO:tensorflow:loss = 0.000208858, step = 38401 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.696\n",
      "INFO:tensorflow:loss = 0.000572009, step = 38501 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.134\n",
      "INFO:tensorflow:loss = 0.000582488, step = 38601 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.862\n",
      "INFO:tensorflow:loss = 0.00041569, step = 38701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.502\n",
      "INFO:tensorflow:loss = 0.000104206, step = 38801 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.42\n",
      "INFO:tensorflow:loss = 0.00130257, step = 38901 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.726\n",
      "INFO:tensorflow:loss = 0.000172498, step = 39001 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.78\n",
      "INFO:tensorflow:loss = 0.000936074, step = 39101 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.228\n",
      "INFO:tensorflow:loss = 0.000516831, step = 39201 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.848\n",
      "INFO:tensorflow:loss = 0.000169603, step = 39301 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.384\n",
      "INFO:tensorflow:loss = 0.000497845, step = 39401 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.831\n",
      "INFO:tensorflow:loss = 0.000112171, step = 39501 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.772\n",
      "INFO:tensorflow:loss = 0.000673415, step = 39601 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.491\n",
      "INFO:tensorflow:loss = 0.000145253, step = 39701 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.621\n",
      "INFO:tensorflow:loss = 0.0010463, step = 39801 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.228\n",
      "INFO:tensorflow:loss = 0.00104107, step = 39901 (0.381 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /tmp/tmp5IuIZf/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000449934.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x7fe5f5f5f5d0>, 'hidden_units': [300, 100], 'feature_columns': (_RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None),), 'embedding_lr_multipliers': None, 'optimizer': None, 'dropout': None, 'gradient_clip_norm': None, 'activation_fn': <function relu at 0x7fe5fa3b39b0>, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300, 100], n_classes=10,\n",
    "                                         feature_columns=feature_columns)\n",
    "dnn_clf.fit(x=X_train, y=y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py:335: calling predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:422: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp5IuIZf/model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98219999999999996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = list(dnn_clf.predict(X_test))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:457: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp5IuIZf/model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.069285509407904705"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_pred_proba = list(dnn_clf.predict_proba(X_test))\n",
    "log_loss(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-8442dafa3532>:1: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-13-8442dafa3532>:1: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-05-27-18:22:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp5IuIZf/model.ckpt-40000\n",
      "INFO:tensorflow:Finished evaluation at 2017-05-27-18:22:08\n",
      "INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.9822, global_step = 40000, loss = 0.0692853\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.98220003, 'global_step': 40000, 'loss': 0.069285303}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using plain TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 1 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"weights\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation==\"relu\":\n",
    "            return tf.nn.relu(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, \"hidden1\", activation=\"relu\")\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, \"hidden2\", activation=\"relu\")\n",
    "    logits = neuron_layer(hidden2, n_outputs, \"output\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.84 Test accuracy: 0.8863 Train loss: 0.560725 Test loss: 0.420663\n",
      "1 Train accuracy: 0.9 Test accuracy: 0.9125 Train loss: 0.406941 Test loss: 0.313086\n",
      "2 Train accuracy: 0.88 Test accuracy: 0.9234 Train loss: 0.355559 Test loss: 0.27104\n",
      "3 Train accuracy: 0.98 Test accuracy: 0.9307 Train loss: 0.167662 Test loss: 0.244759\n",
      "4 Train accuracy: 0.88 Test accuracy: 0.9376 Train loss: 0.334381 Test loss: 0.222338\n",
      "5 Train accuracy: 0.92 Test accuracy: 0.9388 Train loss: 0.340001 Test loss: 0.213575\n",
      "6 Train accuracy: 0.98 Test accuracy: 0.9428 Train loss: 0.185078 Test loss: 0.195933\n",
      "7 Train accuracy: 0.94 Test accuracy: 0.9497 Train loss: 0.163189 Test loss: 0.176292\n",
      "8 Train accuracy: 0.96 Test accuracy: 0.9512 Train loss: 0.180758 Test loss: 0.16531\n",
      "9 Train accuracy: 0.92 Test accuracy: 0.954 Train loss: 0.166193 Test loss: 0.157284\n",
      "10 Train accuracy: 0.94 Test accuracy: 0.9558 Train loss: 0.245756 Test loss: 0.148946\n",
      "11 Train accuracy: 0.98 Test accuracy: 0.9574 Train loss: 0.10059 Test loss: 0.142527\n",
      "12 Train accuracy: 0.98 Test accuracy: 0.9612 Train loss: 0.102754 Test loss: 0.13418\n",
      "13 Train accuracy: 0.94 Test accuracy: 0.9629 Train loss: 0.103076 Test loss: 0.127834\n",
      "14 Train accuracy: 0.98 Test accuracy: 0.9633 Train loss: 0.119461 Test loss: 0.126104\n",
      "15 Train accuracy: 0.98 Test accuracy: 0.965 Train loss: 0.0701536 Test loss: 0.118307\n",
      "16 Train accuracy: 0.98 Test accuracy: 0.966 Train loss: 0.0785718 Test loss: 0.113526\n",
      "17 Train accuracy: 1.0 Test accuracy: 0.9663 Train loss: 0.0269808 Test loss: 0.111071\n",
      "18 Train accuracy: 1.0 Test accuracy: 0.9681 Train loss: 0.0331303 Test loss: 0.106274\n",
      "19 Train accuracy: 0.98 Test accuracy: 0.9695 Train loss: 0.0906488 Test loss: 0.102398\n",
      "20 Train accuracy: 0.98 Test accuracy: 0.9701 Train loss: 0.100966 Test loss: 0.0979431\n",
      "21 Train accuracy: 0.94 Test accuracy: 0.972 Train loss: 0.124088 Test loss: 0.0964243\n",
      "22 Train accuracy: 1.0 Test accuracy: 0.9719 Train loss: 0.0373884 Test loss: 0.0944234\n",
      "23 Train accuracy: 1.0 Test accuracy: 0.9732 Train loss: 0.0321586 Test loss: 0.0910858\n",
      "24 Train accuracy: 0.96 Test accuracy: 0.9735 Train loss: 0.134733 Test loss: 0.0889043\n",
      "25 Train accuracy: 1.0 Test accuracy: 0.973 Train loss: 0.0216515 Test loss: 0.0871632\n",
      "26 Train accuracy: 1.0 Test accuracy: 0.9733 Train loss: 0.0164546 Test loss: 0.0860944\n",
      "27 Train accuracy: 1.0 Test accuracy: 0.9747 Train loss: 0.0209468 Test loss: 0.0849875\n",
      "28 Train accuracy: 0.98 Test accuracy: 0.975 Train loss: 0.0884973 Test loss: 0.0821419\n",
      "29 Train accuracy: 1.0 Test accuracy: 0.9747 Train loss: 0.037584 Test loss: 0.0813486\n",
      "30 Train accuracy: 0.98 Test accuracy: 0.9751 Train loss: 0.0542899 Test loss: 0.0799443\n",
      "31 Train accuracy: 1.0 Test accuracy: 0.9751 Train loss: 0.0249653 Test loss: 0.0808509\n",
      "32 Train accuracy: 1.0 Test accuracy: 0.9764 Train loss: 0.0278096 Test loss: 0.0775802\n",
      "33 Train accuracy: 1.0 Test accuracy: 0.9761 Train loss: 0.0496016 Test loss: 0.0773502\n",
      "34 Train accuracy: 1.0 Test accuracy: 0.9768 Train loss: 0.0145147 Test loss: 0.0755666\n",
      "35 Train accuracy: 0.98 Test accuracy: 0.9773 Train loss: 0.084902 Test loss: 0.0755914\n",
      "36 Train accuracy: 1.0 Test accuracy: 0.9766 Train loss: 0.0246453 Test loss: 0.0767538\n",
      "37 Train accuracy: 1.0 Test accuracy: 0.977 Train loss: 0.0265288 Test loss: 0.0746259\n",
      "38 Train accuracy: 0.98 Test accuracy: 0.9778 Train loss: 0.0460544 Test loss: 0.072788\n",
      "39 Train accuracy: 1.0 Test accuracy: 0.9774 Train loss: 0.011484 Test loss: 0.0714154\n",
      "40 Train accuracy: 1.0 Test accuracy: 0.9782 Train loss: 0.0113662 Test loss: 0.0706166\n",
      "41 Train accuracy: 1.0 Test accuracy: 0.9786 Train loss: 0.0260036 Test loss: 0.0708394\n",
      "42 Train accuracy: 1.0 Test accuracy: 0.9786 Train loss: 0.0143134 Test loss: 0.0702839\n",
      "43 Train accuracy: 1.0 Test accuracy: 0.9792 Train loss: 0.012141 Test loss: 0.0687938\n",
      "44 Train accuracy: 1.0 Test accuracy: 0.9782 Train loss: 0.0125894 Test loss: 0.0707231\n",
      "45 Train accuracy: 0.98 Test accuracy: 0.9788 Train loss: 0.105834 Test loss: 0.0712933\n",
      "46 Train accuracy: 1.0 Test accuracy: 0.9781 Train loss: 0.0251814 Test loss: 0.0683398\n",
      "47 Train accuracy: 1.0 Test accuracy: 0.9787 Train loss: 0.0242258 Test loss: 0.0695365\n",
      "48 Train accuracy: 1.0 Test accuracy: 0.9786 Train loss: 0.00719532 Test loss: 0.0703341\n",
      "49 Train accuracy: 1.0 Test accuracy: 0.9799 Train loss: 0.0472662 Test loss: 0.0678924\n",
      "50 Train accuracy: 1.0 Test accuracy: 0.9789 Train loss: 0.0285617 Test loss: 0.067968\n",
      "51 Train accuracy: 1.0 Test accuracy: 0.9794 Train loss: 0.00836262 Test loss: 0.0677696\n",
      "52 Train accuracy: 1.0 Test accuracy: 0.9789 Train loss: 0.0554695 Test loss: 0.0688519\n",
      "53 Train accuracy: 1.0 Test accuracy: 0.9797 Train loss: 0.0136073 Test loss: 0.0683261\n",
      "54 Train accuracy: 1.0 Test accuracy: 0.9793 Train loss: 0.00281224 Test loss: 0.0666495\n",
      "55 Train accuracy: 1.0 Test accuracy: 0.9799 Train loss: 0.0106019 Test loss: 0.0669816\n",
      "56 Train accuracy: 0.98 Test accuracy: 0.9797 Train loss: 0.0789602 Test loss: 0.0672601\n",
      "57 Train accuracy: 1.0 Test accuracy: 0.9794 Train loss: 0.0146086 Test loss: 0.0665276\n",
      "58 Train accuracy: 1.0 Test accuracy: 0.9791 Train loss: 0.0179766 Test loss: 0.0689015\n",
      "59 Train accuracy: 1.0 Test accuracy: 0.9796 Train loss: 0.0106541 Test loss: 0.0668389\n",
      "60 Train accuracy: 1.0 Test accuracy: 0.9799 Train loss: 0.0139816 Test loss: 0.066232\n",
      "61 Train accuracy: 0.98 Test accuracy: 0.9793 Train loss: 0.157813 Test loss: 0.0663762\n",
      "62 Train accuracy: 1.0 Test accuracy: 0.9802 Train loss: 0.0240117 Test loss: 0.0658079\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            _, closs = sess.run([training_op, loss], feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        loss_test = loss.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test,\n",
    "              \"Train loss:\", closs, \"Test loss:\", loss_test)\n",
    "        if acc_test >= .98:\n",
    "            break\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_path) #\"my_model_final.ckpt\")\n",
    "    X_new_scaled = mnist.test.images[:20]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    print(np.argmax(Z, axis=1))\n",
    "    print(mnist.test.labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `dense()` instead of `neuron_layer()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tensorflow.contrib.layers.fully_connected()` rather than `tf.layers.dense()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dense()`, because anything in the contrib module may change or be deleted without notice. The `dense()` function is almost identical to the `fully_connected()` function, except for a few minor differences:\n",
    "* several parameters are renamed: `scope` becomes `name`, `activation_fn` becomes `activation` (and similarly the `_fn` suffix is removed from other parameters such as `normalizer_fn`), `weights_initializer` becomes `kernel_initializer`, etc.\n",
    "* the default `activation` is now `None` rather than `tf.nn.relu`.\n",
    "* a few more differences are presented in chapter 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "n_batches = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. Draw an ANN using the original artificial neurons (like the ones in Figure 10-3) that computes A âŠ• B (where âŠ• represents the XOR operation). Hint: A âŠ• B = (A âˆ§ Â¬ B) âˆ¨ (Â¬ A âˆ§ B).\n",
    "\n",
    "Edge labels indicate number of connections. E.g., '++' means two excitatory connections, '-' indicates an inverted connection, i.e., one which is excitatory when its input is off and vice versa. The node at the bolded end of an edge is the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD/CAYAAAD/qh1PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl81OW1+PHPCVlICGAoIloWNxbR3uJy60pVXCtSvEpL\nrVjlZ61WrSu11mqtl+tSC+7lWrVVcatWBKV6BZdaRWsrWhX3Fa3gWnYyhJA5vz/ONxCSySzJd+Y7\n8815v17zApLJdx6SyZlnnuec84iq4pxzLr7Koh6Ac865/PJA75xzMeeB3jnnYs4DvXPOxZwHeuec\nizkP9M45F3Me6J1zLuY80DvnXMx5oHfOuZjzQO+cczHngd4552LOA71zzsWcB3rnnIu58qgH4FyX\nIlIGbAcMBaqBSmAdkADeBt5DNRndAF0ceaB3Lp8ssB8AjAFGATsASWA9IMFNg1s5UIbIG8DTwEPA\n4x74XWeJ96N3Lg9E6oBJwGSgJ9ADC+rZUmANsBKYBtyC6rKwh+m6Bg/0zoVJpAb4NfBDbOZeE8JV\n67H9tJuBn6FaH8I1XRfigd65sIiMAv4I1GHr72FLAMuACajOz8P1XUx51o1znSVShch0YC6wFfkJ\n8gTX3QqYh8h0RKry9DguZnxG71xniNQC84CR5C/Ap5IA/gkcgurqAj6uK0Ee6J3rKAvy84FhQPcI\nRrAWeAvYx4O9S8eXbpzrCFs2mUd0QZ7gcYcBc30Zx6Xjgd65jrkKW66JKsg36w7sDFwZ8ThcEfOl\nG+dyZdk1cynsmnwmCeBgz8ZxqXigdy4Xlif/Dpb9UmyWAEM8z9615ks3zuXmCixPvhjVAZdHPQhX\nfHxG71y2rK3BEqJfl09nLbCVt0twLfmM3rnsTcLaGhSzJHB81INwxcVn9M5lw7pQfgxsGfVQsrAE\nGOhdL10zn9E7l50DsC6UpaAXMDrqQbji4YHeueyMwVoNl4Ia4LCoB+GKhwd657Izitz6yWe0H5Ym\n0xDmRU0Z8M3wL+tKlQd65zKx9fkRYV5yEXaElAAPhnnhjUYgEuoLkytdHuidy2w7oCnMC84A9sDS\nY24L88IbJbFxO+eB3rksDMXOeA3NDOCY4DYX+CzMi5v12Lid80DvXBaqCXF9fj7wIfBdYFds2n1X\nWBffSCiuXjwuQh7oncuskhAD/W3AwUDf4N/fJy/LNwJ462IHQHnUA3CuBKwDQqksTAD3Ygv+/YOP\nNQDLgZeBr4fxIEbJS0KPK0U+o3cuswQhBfrZQDfgdeCl4PYGlrs5I4wH2EixcTvngd65LLxNSO9+\nb8Ma5gzCZvTNt9OAOwl1x7ccG7dz3uvGuYwsj341pbW5mQB64L/gDp/RO5eZNQd7I+ph5Oh1D/Ku\nmQd657LzNCGt0xdAEngq6kG44uGB3rnsPASsiXoQWaoHHo56EK54+Bq9c9kQKVP4WLwfvStBPqN3\nLgMRKRMYOwUaE8W/fFMPTPUg71ryQO9cO0SkXESOAV4BfjkTLuhe/EVIZcCtUQ/CFRevjHWuFRGp\nwhpLnosdH3gOMO9lVUXkG8AJFGeqZQK42Q8Gd635Gr1zARGpBX6EBfaXgMtUdX6rO9UA7wBbFXyA\nmS0GhqJaH/VAXHHxpRvX5YlIHxH5JfA+sDtwuKqOaRPkgSCITqD42gskgAke5F0qHuhdlyUiW4rI\nFdgMfTAwSlUnqOo/036hvQDcSpEE+0ZoVLgF1WeiHosrTh7oXZcjItuIyHTgNaA7sLOqnqCqb+Vw\nmbOAfwJr8zHGbCWhYSGs6wk1IlIZ5Vhc8fJA77oMEdlBRGYAC7DOwMNV9XRV/Sjni6k2AIcAbxFd\nsF9bBm8+BNutgT7AIyJSF9FYXBHzQO9iT0R2E5GZwJPAm8B2qnq+qn7eqQurrgb2wWb2hV7GSQAv\nAvtcqPoZcGQwjudEZPsCj8UVOQ/0LpbE7Csic4FZwF+BbVT1UlVdHtoDWbDfH7iFwgX7RPB4o4PH\nR1WbVPUc4EpgvoiMKtBYXAnw9EoXKyIiwGHA+UA/4HLgdlVdV4AH3we4B6gjP3n2CWAZll3TNiNo\nwzDkIKy9/TmqensexuFKjAd6Fwsi0g04CgvwAlwK3KeqTQUeSA324nIi1kWyJoSr1mPvvm8Czssm\nhVJERgB/xgL+ReotEbo0D/SupAWZJhOB84AvgUuAhzXqJ7Ztih4PTAZ6YQE/l6XSJBbgVwJTgVtz\nrXgVkX7Y6YUfAZNUtSjSQV3heaB3JUls5vxDLJC+gc3gn4o8wLdmp1MdAHwL+CYwAgvi67F3HoI1\nSlOsJUkZdqTsU1ir4Sc606BMRLpj6/lbA0eobdy6LsYDvSspIrIZcApwBvAMcKmqLoh2VDmwwL8t\nMBRbx6/CGqUlsDNe3wv7ZKhg3+JXwA+wqt/Xwry+K34e6F1JCJYhzgROwg4BuVxVX492VKVFRCZi\nWTnHqurcqMfjCsfTK11RE5GBInINlv++GbCbqv7Ag3zuVPUOLN/+NhH5cdTjcYXjgd4VJREZKiK/\nx7pINgA7quopqvpBxEMraUGjtr2BM0TkyiBbycWcB3oXhnJgF6BHZy8kIiNF5B5s/f0jYIiqnquq\nn3T22s6o6nvAnsBIYFbQntnFmAd61xlfwdIZl2KVp18C92FLLDkRkb1E5CEs0+QfwLaqerGqLg1x\nvC6glqp5KPA58LSIDIh4SC6PfDPWdUQ/4ELspCXYtAq0AZgJHJPpIkE2yEFYkdMg4NfAbaoaaUfI\nriT4GfwUOB0Yp6ovRDwklwce6F2uRmEVl1XBLZUEsCuW396GWIrhEViAr8Zy4O9R1fWhj9ZlRUSO\nBH4HnKiqs6MejwuXB3qXq+ewU5jSWQ/cj53EtIGIVABHY1Wsq7EA/6CX5xcHEdkNq6S9Criy6IrP\nXId5oHe56IdtkLY3k29pLbADsCiozpyEHbb9ARbgH/dAUnxEZCD2ju3vwKmq2hjxkFwIPNC7XNQB\nnwLZnGTUmEgk7qqpqXkNO41pAXbY9t/yOUDXeSLSE7gbO31rfKhtnV0kPOvG5WIZ8DesL0smFcBx\n22233Z7Aoar6bQ/ypUFVVwHjgFeBv4nIthEPyXWSz+hdrkYB/0cWOfPJZHJdWVnZ9cA5eR+VywsR\nORW4AJvZZzp8fDB24lZf7Dzex/I8PJclD/SuI/6JFdtkox4YgL0bcCVIRA4FZgBnqupd7dxtL+AR\nrBtnBdAEzMFaNXu6bMR86cZ1xPlY1swGCxYs4MADD+TNN99sfV/BOk26EqWqjwCjgUtF5KIg976l\nYViQ7wnUYpv1NcC3gWeBzQs4XJeCB3qXs4qKin8vXrx4wy/7q6++ygMPPMDUqVMZPnx467tXY0s3\nnW6P4KKjqq8Ce2DHNN4eZFKBLdP8hdQ/32pgR+BloM0TwxWOB3qXleCw7dEi8tj69ev/dOedd96j\nwcHUO+20E1OmTGHkyHZXcxQYW7DBurxQ1U+B/bCsq8dGjx79VWAu1gqjvVhSCWyBtbU4oADDdCn4\nGr1LK6hiPRxbrtkMOw/1ruAs1g+Br2ZxmfVYe4ML8jVOVzgiUiYiUx544IEzxowZ062srKx75q8C\nrGL6DOzsW1dA5VEPwBUnESkHvgP8HAvUlwKzWh22fSFwLbYum04DVnHpYiCoZG5sbGwsLysra7d4\nbulS60fXp0+f5g9VA1djxymeTXZpui4EvnTjNiEiVSJyInbQxylYNeuuqnpfqyAPcCeZMyrqgfcA\nb5YVH98DflpRUbFJkE8mk0ydOnXDv2fNmsXkyZNZvXqTffsa4ERs4uAKxAO9A0BEeojIWVhQPhKY\npKqjVPWRNK0K1gG/ANak+Fx98PGrgG/gs7e42BP4Axaw25g/fz4TJkxgzpw5vPjii4wfP57a2jZv\n+HpgM3pXIB7ouzgRqRORC4D3sVzob6vqt1T16SwvcTPWi35tcFsZ3C7F1u8vwJZuXOnrh50XUN36\nE8lkkrKyMmbPnk1FRQUnn3wyw4cP57DDDiOZTKY677wb7bxYuPD5Gn0XJSJbYD1oTgQeBPZV1TZJ\n8FlIAmOAbYD/wl4w5mIbby5eptFOcC4rK6OxsZH333+fQYMGsddee3Hbbbex2267seeee6b6En/x\nLyAP9F2MiAzGDpr4PrbGvouqfhjCpT8ArgzhOq54DSRNQ7svvviC66+/nrq6Ov70pz/x8MMPc//9\n9zNixAh69+7d8q5rgMnY8p4rAE+v7CJEZDjWB34scCNwtap+Fu2oXIn5I63OGGhtxowZjBs3bkNg\nTyQSVFdvstJTjx03eTy+b1MwHuhjTkR2xVIkv4mlQv42OC/UuVztRztr9K01NTXRrVu31h9uAF4E\n9gW8z30B+WZsTInIKBF5BHgAmA9so6r/40HedcKT2FnAGZdcWgf5pqYmDd5BHoYH+YLzNfqWrAp0\nO2AoNmupxFIIE8DbwHsU8bF3QbOpQ7Eq1i2xKtZxquobXy4ss4D9sSZmvbDsmYwSiUTTnnvuuejV\nV1/1g8Ui0LWXbiywH4BljYzCjr5LYpWgEtw0uJVj74DeAJ4GHgIeL4bALyLdsNz387FfvEuB+/yw\nbZdHg4EngK2wk6jSqV+1atWhvXr1moAt/xyuqovyOzzXUtcM9CJ12Bmmk7HWqj2woJ4txTIHVmIp\nZ7cQwZJIcNj2RGyTdRlwCfCQH7btCqQXlpr7n7SfE18P/AjL8EJETseer0eq6nOFGKTraoFepAZr\nrvVDbOYeRsFGPTbTvxn4Gap5SRkTkf/ANlWnY+evnoClSb6NzeCf9PfELgLl2HPyGNr+Pq3Betts\n0sxORA4HbgFOU9V7CjHIrq7rBHqRUVh6WB1ZZA10QAKbVU9AdX5YFxWRPbElmcODD70N9MbObr1M\nVf8R1mM51wlnAJdhyzjrsb2te7BJVZsgIyJfx06g+h1wqU9S8iv+gV6kCuu3cjz5CfCtJYBbgbPo\n4CZosKl6IBbg90txl++q6p86OkDn8mQE8ANgKTYheYA0ufIisiUW7F8DfuRJA/kT70AvUgvMw843\nLUSQb5bAzlU9hOBwjmwEvd/HYQF+tzR3vUpVvSmUK3ki0gO4HTup6r9U9d8RDymW4ptHb0F+PrAz\nhQ3yBI+3CzA/GEdaIlIuIhOBhcD9tB/k/46dwzk5rIE6FyVVXQOMx5YinxORYREPKZbiOaO35Zq/\nYEE+29Nv8mEtVgk4OtUyTnDu5vFYz/dt0lznMXzD1cWciJyAPc8nqOqTEQ8nVuIa6KdTuDX5TBJY\n+uWpzR8QkZ7ASdih2f3TfO1sfMO18Eq8cK6Uicho4G7gPFW9JerxxEX8Ar1l18ylOIJ8swRwsMDr\nwOnBra6d+yaxJ/rlqvpqgcbXtcWkcC4uggZ8fwbuBS7wupDOi1egtzz5d7BqvaKyAlZvBVJvxVmp\nrMNyi3+jqu8VcGhdV0wK5+JIRPpi7RY+BY7TPNWndBVx24y9gvZnypGqgNrLUwf5NViQ2EZVT/Yg\nXwAiNYhcBywBpmB9gWrJLcgT3L8Wm1hMAZYgcl0w4XCdoKpfYinGa4EnRSTdEqfLID4zepudLSHa\nzde0ElhEWG7/XI61Db7WU8oKqEQL57qqoKbkAqwSfKyqLox4SCUpTjP6Sdi6atFKAifBKizLZpCq\nXuRBvkBEqoJN+rnY622+9nCqg+vPQ2R6kAHmOkjNFKz9x+Mi8q2ox1SK4jGjt820j7G34EVN4ROB\nAb55V0AlVjjnUhORvYCZwCWqen3U4yklcZnRH4BtphU9sXGOjnocXUYJFc659FT1WWAv4BQRuTYo\nNBQR6RP12IpdXAL9GNrPZik2NdgpOy7fbNlkHjCM6PZuugePP9eXcTpPVT/Agv1wrJfORcArIjIy\n0oEVubgs3byAzZw6ZD/gZSyPK9ffxK2Bz7DTPiqwZ+ANwMD0X/YCqul62eRbGdYN86tYWudSbANx\naYu/11PqhzcXeeGc67jgLIaHgIOCD60BjlbVOSE+SGwK50o/0NsPYw0dnLEtwn6SvbF+qd/J8eu3\nxhrRN+eBnYJFytnpvywB9CCab353rH3sAVjATwJNWFAXrCCoMvh7c474ciz4f4G9rn3KxheEL7B1\n6C8K+Z/IqIgL5zwbp/NEZEfsXIaWv/cKnA1c06FWIXEunFPV0r7BEIXVCtqR28Wge4GeBTqmnfs8\nA9ojuG/rzw0GfbTFvx8CHZL5cVcrbB/R9+xWVa3XzkmqakJVV6rqclVtUNWfRfo82PQ5UaOwuKPP\niTzfFivURP49KvEb9ib6ajYG3pa36UB5Ds+XOoWzFZYorFJI5vgzTQZftzi4Tl3U35/Wtzis0Q/F\nXnE7ZAZ2NM4x2PTvsxT3eQCbFt6f4Vr12FR5j8wPux4bdxQOpvOzXMFmUj2xN0OV2Frp+E5eNyxF\nWziHjevyqAdR6lS1SVXPBE6jbVr1j4GHRKR32ot0ocK5OAT6alL8YEZj3/nWtxrsvRlYKsaHwHeB\nXbElnLtSPMCD2NE5rwMfpfj8EcBmWMR7FDvfLwMhuiWFzfN03WrsbXO0rHDuBIpryaalauDEYJyu\nk1T1t9hSy6pWnzoYeFZEtk75hba09w72XOlOOMeKElyne3DddxDZJ6TrdkocAn3zevImngBWp7g9\njC1IA9yGPRv6Bv/+fvCxlt4FPgC+hy3aPZhiALOxRey1wPXAvtgidhpC7vu+YUj5ogiwYsUKpk+f\nzuOPP57yCxctWsTixYszXb8YUlyLvnAOG9/xUQ8iLlT1ESwPovU8bATwdxHZ+Ca7ixbOxSHQr6MD\n2SEJrDXeX7E+wf2x8wZfDm7NHsTeAdRiRz+l29LvBhwZ/Jlut2011JwMZ4vI7SJyjYhcJCKni8hE\nERkjInuKyDAR6RdkF4SlDvt+tZFIJHjjjTdYunQpAOvX22pYQ4O10Z8yZQrXXXfdJp9LYUWIY82d\nbaZNJrzZWb7UAJOD8boQqHV63R1o3dK7H9YrZ0JQy/AXCpuJVR083hNR1lKUR/XAIUqQQ6DfFvgR\nNgvvhh3pVNni89/F1u2nBf9+EJvpgx3tdC72HjHV1FWD+y/Dtuvb0x0SO1ob1g+w4NsHW7Nv/nvz\nn32AzUQkwaapj6nSIVN9bJUGO1eBOqCRFE/yXr16UVtbyw472MjLy+2pUVVlE5GKigp23HHHTT6X\nwpdp/tuFUDKFc0AvbIXxsagHEheq+qmI7Ie9MW+ZQFfVA/64BD7dEjaTwtdUtCyc24cIqqTjEOjf\nJof/xyAscB+Kvccf1Orzp2HN4n+NBfRnsebwYKmUw4FH2PRZNBZ70RBgMPYs2zHNGMpBfgJ3/ET1\n3UzjDc6R7cmmwb/lC8JXgO3b+Vx3EVlOEPjHjh2rd999d3WPHhtry2666SauvvpqamtrWbJkCQsW\nLKBfv35MnDiRzTffnIULFzJgwAAWLlzI9ttvz8qVK2lqaqKuLuUSc6q97EIqxcI5D/QhUtWEiHwP\niwu/AJvIzQPqoH+uu6whalk4l/LEuXyKSx79aop38y2VguTRi0glFvDrgD433HDDoZMmTZpcWVm5\n4XuVTCapr6/n+eef55prruHII4+kurqa7bffnoaGBubMmcPSpUuZOXMmW2+9NVVVVfTr14+rrrqK\nQYM2vkyqqq5ateo3vXv3/rmGmEsctKetp+27k1R3zrpwbj86XiR3PLZp37w5NBS4EtubyVHUhXNV\n2H9nS6CBtu8Mm/9cSfHve7QhIscBN/0WKo6naNbzIimcK/0ZvWoSkTfoRGVsBF7Pd5AHUNV12Cy7\neaY9lI170QCUlZVRW1vLwIED6d+/P+PHj6emZuOvxB572D7Wyy+/zMyZM9lyy9R949atW8fFF198\nOnCOiKwgt6WmZcBSVV2b4tKPY5tqTSLS7rXKYXkCvpbNE3oRVuHSG1tqa/nurDkJ+3ZsHepr2LSw\ndTQ+F/if4P6/x/ZmPsfe2eVgBCJSiOdCCnXYm9OdsElSEgv269m4FNoNez0rx3INVmH7MMuwb8/n\nwCfAv9lYOPcaHdgzywdVve0qkZ7Hw3VFEuTBvteTELmbAhbOlX6gN09jTasifGeWtSTwVESPXcem\nWxIbfPnll3zyySc0NDRQU1OzIfY0NjZSWVnJhx9+SGNjI2BFdtYmfKOqqqo106ZNO/XKK6+8C8s2\nTbWU1Adb3RqZ6nMi0kTbF4HmQ9O7YQlSzUlSm9gai0TZ7HbNwGoddqftYu5xWLT7DVbyOBCYiG3U\np+qPK9hS4InYq2mOR5slsazejEt4eXAL9nNofj50I/2ktya4bZHic+uwb1s34H+xDfHoidScZe2N\ni001cA8iQyjQyVlxCfQPYXmrpdAhsB7L8ozCV7CWPG3ssssuXHvttRvW3psDeWWlxYH999+ffv36\nbfK5VpqwWfl6bLaX08ZscMBEDW1fGMZk8/W5VM3NwBL+d8cC/mdY9HoYq5x5FFvWuRGrsd8mGMRb\ntP2FaQqutw2pI2AGzYVzUQT6UbTzot8BlS2u9WOs5OQPIV27M0qhcO70QjxYXNK7HqdtwUSxWoml\n+UdhC9p511NZWcngwYPb/cI77riD7t0zJit0+LxUNWtU9WNVfUVV/4rF3s+wF8e02i0QaCVdkdxc\n4P+luM5w7B1Dy5Pap2JvW2qBM7FyyByXbVgHlbfBniKyu4gMEZG+IlKIyZdgw8+HGizPIVpeOLeJ\neAR62/ybShYBIWL1wFSia3yUag08LGXYUkto1HroDFDVHljWwpZYQtM+WLbr8cBZwJThMK8yi0l9\nuiK59dgrsGDrgC8Efx+A7Vo2trjOZKxIrh6b9f8U+L8c/39roXquHZP3HJYl8gXQKCIrROQDEXlR\nRB4TkW3SXylnPWm1V9MspMK5Ysh88sK5FuKydAO25nhJ1IPIoAy4NcLHfwybtOZjb6oK25zLC7V0\ntE9pr+hYZDy2EtOrvWs0F8k1YQVyYAvLy7Glmn2B+7CdxJeAH2JBfDGwN/AfqR4W283cG1s/zOWc\nOw0eP4VewW3r4N/bBbUUyzSctLzmwrk2y3j19fW88cYbG5bp1q9fT3l5OQ0NDVRVVXHxxRfTv39/\nLrvssg2fS2F5CGPsuNIrnLsm35O/+AR61WWI3Ezxvl1LADej2uHljRA8gO0rnokF5jB//kux7Iuo\nZCycy1Qk9xvgJuAc4FhsDX8hNuX6b9pPw3wTWxL6ZY4D1mDQWfgtliTUR0QaaT8NMt2fK1S1eRbf\nh3Zm9L1796a2tpbhw4cDbQvnqqqqGDFixCafSyHqltVeONdKfAK9+RmW6VaMgX4pcF7UgwAuxLJ+\n9sT2EDfHVjLqsGDSk40rFY1sDAhl2POlik2X/BTbH4m6c2XGwrnbyFwkNwf4FbYu1IjV01+MndLS\n0hVs7JH7leC6J+U44O7QtBj+hj1fmzefe7PpNkETMFxVtcWGdapspuY/B7Tz8Z4isgpYOnbs2PV3\n3XVXTW3txtyFdIVzffv23VA498orrzBkyBCWLbP5SjuFcxlaPeWdF861UvoFU61Zt7h5FFGwb4TG\nCtgf1WeiHkuWumEBp71q3C2CWy9ss/QSrBNgdGJSOCcirb/3PVW105v3La7bZ86cOUcdcsghv6yo\nqNiwtNFcOLdgwQKuvvpqjjrqKLp3796Rwrnku+++e+3QoUMvw5aaGtuOJs/SFM7tR8cL5bKxNcV5\n4lzcZvSgOh+RWymSI+TqgVug4jT4LiLPtXj7XMya2FiQ9F7EY8lOTArngudH6N/7Vtdts2neXDg3\nYMAA+vfvz1FHHZWycO6ll15i9uzZbLFF6mTStWvXcsMNNxyNlR9sJiJryby0lOpjqzpUYW0v+CNS\nfWoR7RfKhWkOm5449xMynjiX98K5+AV6cxbwdeyXPqpDoUlgpYJBk/bTsU21o1W1VFJBS40XzmWn\nD+3k0P/73/9OWzj30Ucfbehomqpwrrq6es20adPOnDZt2h+DpaaWfZpS/blNOx/vEfRpymk/YiH0\n2amd/Yd0hXJgfa0Oxqqec91vSaU7tp55Zua75r1wLp6BXrUBkUOwPbJhRBDsm2Dd21B+CJS16As8\nBpgvImNVNdUZJq5zvHAuO31p53d/5513Tls4N3r06EyFc0mCdwxBb6KVwe3DXAYY1BM0V1ineiEY\niCVCbfLxn0Pf26EiVZFAe4VyzVqeJBdGoO/AiXP5K5yL+izDvN6gVuFZhfoCnwtar/DMbrbh+S/a\nnmn5CfCfkX9/4naDsuDcz0L+rDt6W6xQFtH3aobmz3JVje65DeOTsKL19/tp0HLQL4J/DwO9stV9\nhoPeBFoB+mGrz+2PnRvd+lYNOrrF/QYHH+8dPN6WoK9kfi6sUDgqn9+XeBRMtcf6Pu+P5dhnmcnW\naYng8UY/r/o34BtY7U1L/YG/ishRBRpT1+CFc9nKZz/0boRcOJejSkmxdJfpNLlMJ8llc2Jds2I8\ncS7egR5sGcdagh6MtTLJV8BPBNc/GNVTCQpbVPUT7Gc9q9X9q4H7ROQ8aec9sOuQWyj+53XUhXMP\nkL/fg7wWzmWhzYlz2Zwml8tJctnK9sS5YLx57U9f7L8Q4bGWoEOAm7EX27BmffXB9W4GhpCi9aiq\nrsH2Za5I8fWXAb8Pese7zrKCtJsp3Du4XCWAm4i2cG4u1nqhPriFle2RxJYqo0w2aFM411wo9zpW\n8fwS1pl0FLZuDxboxwV//zb2opDNf6L5xLpUFHtFzXTiXHDXvD5f45dHnw1rJHQ8VibdCytayOVF\nL4n9gqzElgpuzfYXV0ROwFJrW2+GnaSqN+YwBtcekRosrz/HrsEFsRgYSoHa02awM7Y32R/bl+yP\nrW70wTZCe2KFR03YTLkJC0rCxl71zW0U1mOV0fthxcLREBmCJbttKJg6FGuQNK3VXe/FUuEWAl/F\ndoubT1sYiZ1DkGsK5tZszKNvPnHu58Ax6b9sDTCSLE6c66iuGeibWc7tAViLkm9i+bdJ7Ekrwa15\nA7UcezF4HUuLexh4oiPrrCKyP7a535wc8C9gmKoW6yy09BRh4Rw2azuI0imcA/sd6EH72S992Vg4\n979EfZw03x99AAAQWElEQVRkTArnwta1A31r9iTZFkt1qsbWGxuwH8TbwHth/TBEZBiWDrgcq+XY\nEjhCVaPuExIfItMpksI5IjpCrkvK4UjJIuGVsQVls/N3KcBBEKr6lojsgf0MPsdaqvxdRA5X1dfz\n/fhdRFEUzmF7OC1q51yeeeFcK11nM7YIqeqXqvqpqiZV9UKsn9aTInJQxEOLB8t8OgQ7HCqfvfjT\nWRs8/iGE02LYZXAfvJ5opzq2CBWkcM6XboqMiHwT2ye6SFV/F/V4YkGkFluvH0lhl3Gau2AcEtR0\nuDwK3iGfLzD2Y4pzJz6FJcDAfNdU+Iy+yKjqU9gJSmeLyLSg66DrjIgL5zzI54+YA0TkCazl81jF\nUuHWRDu0bBSscM5n9EVKRPpgBx6tAo5RDxbhsGyce7CMkXzM7hNY6vSEVDUVLhxiiRNjgfOx6vNN\nbIZNlYthFz6NtcBWhaip8Bl9kVLVpVgK8JfA0yIyIOIhxUOEhXOu80SkXES+jxW1ziZFkAdYDv94\nGx5SL5wDfEZf9IL2COdiba3HqWrrvjmuoyIsnHO5EZEq4DjsFLlt09z1CeBS4Am1Cb0XzuGBvmQE\nDdBuAE5U1QznGLicRFQ45zITkR5Yl4HJpA/YDwKXqepzrS7ghXN4oC8pIrIb9nb1KuBK9R9efhSw\ncM6lJvZu6zTgDOxY3lSS2H7L5ar6SpqLdfnCOQ/0JUZEBgJ/Bv4OnKpRnMnpXJ6IyBZYodspWK+d\nVBqx7p9XaDb9YWzZ5wmKo3DuRSwTq6A1FR7oS5CI9ATuxp6031FfF3YxICJjsEyz9oJxAvgdME1V\nP87x4rVEeOIcGwvn9oki3dazbkqQ2pmz44BXgWdFZLssvuyr2FGGx2PN/JwrNi+Sum3BCuB/gMGq\nelbOQR6aayn2wQrYCp2Jk8D+b5EEefBAX7JUtUlVzwSuw86h3TvN3UdhLbjvDO7/PPDflEYvEBdz\nItJDRM4A/oEds9nsC6zL72BVvbDTDf+6cOGcL93EgIgcip2hcJaq3tnq0zsCz9H2wOw1wKPA0UTX\nB8Z1YSKyGXAq1hZ+PpYW+SnwJHAt8HvNV/phFyuc80AfEyKyE3YC2gzgV0FGzhbAK8DmpJ69N2eR\nHEy0x7+5LkRE+gFnAidhiQW/btmxVUSkIBlldkDN5cCJWAZPTQhXrcdWSm4CziuSA2Z86SYuVPVV\nYA+sW+OdV1xxxWbYjL2O9pdoqrGc8VeCP53LGxEZJCLXYidQbQbsqqrHtW7LXbC0YdV6VE/H8vMv\nwLomrMaCfi6SwdctCa6zFaqnF0uQB5/Rx46IVHfr1u3WefPmHbT//vtXi0g2GQaKLeUcib04OBca\nERmKVbQeAfweuEpVP0n/VRGIceGcHzwSM6qaSCaT7zc2NtaKSEXmrwDsCVyLnWV8DnYknHOdIiIj\nsc3U0cD1wJCgh1NxsiD9KM2TnRgVzvmMPn6OxVolpF1vXLrUft/69OnT+lP1WEXiLXkYm+sCRGQv\n7GztnbEzuW8MUoJdRHyNPl72wQpK2gT5ZDLJ1KlTN/x71qxZTJ48mdWr22R8NW9QOZe1oC/8wSLy\nJJbGOwfYVlWneZCPni/dxMcALIOh3VSx+fPn8/zzzzNx4kRefPFFxo8fT21t66xLAHrna5AuXoK+\n8OOwvvA1wGXAH1V1faQDc5vwGX18/JZ2lmuSySRlZWXMnj2biooKTj75ZIYNG8Zhhx1GMplMtcy4\nDi+miqv+wH8B/TpzERGpEJFjsersX2A58F9T1Ts8yBcfD/TxMQxIuflaVlZGY2Mjb731FoMGDWLv\nvfdmxowZPPvss5SVlWEt7zdYgxWx+OZNvOwKPAIswhqCfQQ8TttCurREpLuInIxtRp6AdZf8T1Wd\npUWaceI80MdJ2vLwzz//nOuuu47y8nLuvfdepkyZwqxZs1ixYkXLu9Vj66u353OgrqB2w6pOnwIO\nwjJHegV/7oVtlmYkIrUiMhl4HzgcmKiq+6nqo94uu/h51k18/ABLi2w322bGjBmMGzeO3r1tCT6R\nSFBdvWFJfy3W+vhALG/Ylb5TsJOvutP+UtxaLH3wX6k+GZxd/BMsE+sJ7HCPl8IfqssnD/Txci7w\nKzL07mhqaqJbt24t/50sKyv7QER2wY7Fc6WvDGtr0d6hHc3WAX8AftzygyKyJXA2tjwzC2tT8HYe\nxukKwJdu4uUKLI8+bel1yyAPsHr1av3617/+DxEp1oOUXe6+AVRmcb9K7CzWfgAiso3YiUyvBZ8b\nqaoneJAvbR7o42cmsB+wlOyWYOqXLFly4MKFC3sB/xcc4eZK3+dknz4tH3744WUiMgNYACwHhqvq\nGar6Ud5G6ArGA308PQ+MxDIs0rUgTgDH7bDDDk9iudALyf4gE1fc3gfeyfK+3fv27Ttp8ODBi4Dt\nVPV8VfVupjHigT6+/oWdkfk3LGWytTVY7vN9sOEgk7Owg0meEevX7UrbL7CuihnV1NSsXbRoUaOq\nLs/zmFwEPNDH2yospW4Gm67br8HOnL2k9Reo6nTsuMH7RWRiAcbo8uchUpwzsGDBAkaPHs2bb765\n4WMiUg38lHB6srsi41k3XccBwETsBJ9XgD+SpiiqnYNMXOn5nqreJHY4NgsXLuTee+/lqKOOYuTI\nka3vuwZ7F3BNoQfp8ssDvWuXiGwBzAY+AP6fqvqRgyVERCqqqqqO/eijj27s169ft8xfAdgmfn+g\nMY9DcwXmSzeuXar6GdZLvAx4IjgCzhU5EakWkdOAdxsaGo5+4YUXrtTsD6YuB/bN4/BcBLx7pUtL\nVRMi8n3gYuA5ETm89dFvrjiISC+sGvZM7ED476rq37F8+BOyvEwZ1gnVxYjP6F1GqppU1Quxqtsn\nReTgiIfkWhCRviIyBUup3Ak4UFWPCII8WPXrFFJnX7VWATyYn5G6qHigd1lT1RnAUcCMoIOhi5CI\nfFVErsQ6SfYDdlfVicFB8a3dSOZDr9dgm+/Fe9yf6xAP9C4nqvo0dpLVmSJypYhku8nnQiIi24vI\njViBm2J94E9S1ffSfFk9tvyWala/GttwPxb4UdjjddHzrBvXIUGrhJlYkPh+Dpt9roNE5GvAecAh\nwHTgWlX9ModLdAPuBcZgyzndsAD/c+x0Mg8GMeWB3nWYiFRiAWdXYKyqfhzxkGJJRHbHjurbHbgK\n+F9V7UyX0T7AwcDLwBudH6Erdh7oXaeIHU/1U+B0YJyqvhDxkGIh+L7ujwX4IVhn0j+oqncYdTnz\nQO9CISJHAr8DTlTV2VGPp1QFh20fjgX4zYDLgTtV1QuYXId5Hr0LhareLyIfAbNFZHtgmrdNyJ6I\nlAPfwdbL12MN52apalOkA3Ox4DN6FyoRGYj1yHkeOMVnoumJSBWW7XIe1ofoEuARf5F0YfJA70In\nIj2x7pjdge+o6rI8PEgZsB123mk1Vv25Duux/zbwHqqZ8sYjIyI9gBOBycCrwCVB6qpzofNA7/Ii\nyK+fCnwLGJMhxzubC5ZhHTjHAKOAHbACoPXYwdeCpQcqtiRZhmWUPI216328GAK/iGwGnIptXj+N\nHbbtG9gurzzQu7wSkR8DFwHjVXV+By5QB0zCZr49gR5YUM+WYkVCK4FpwC3k4x1GBkEn0DOxgqQ/\nA5erqqc2uoLwQO/yTkQOAW4HzlbVO7L8ohrg18APsZl7GAdi1GMz/ZuBn6Ga9hD1MIjIIOxFaiK2\nnPUbVV2U78d1riUP9K4gRGRHbCab+SATkVHYwSh12Pp72BLAMmACHXmXkQURGYptsI7DXliuUtVP\n8/FYzmXivW5cQajqa8AeWEXmXSLSvc2dRKoQmQ7MBbYiP0Ge4LpbAfMQmY5lvoRCREaKyD3AfOxw\n9u1V9Wce5F2UfEbvCio4m/QWYBBwhKp+HnyiFpgHjCR/AT6VBPBP4BA60a9HRPbGipxGYnsBN3r/\nH1csPNC7gguqPy/G1q0PV/gQmwEPw1IyC20t8BawTy7BPmhTcBB2zupAbE/hNj9y0RUbD/QuMiJy\nbBVMWwxffgW2IZog32wt8CIwGtWGdHcMXqiOwGbw1VgV6z2quj7vo3SuAzzQu0i9IzJrABxRyLWa\nNBJY+uWpqT4pIhXA97A2BWuwKtYHtQjy851LxwO9i45l18ylsGvymSSAg1tm4wQbx5OAc7EN1kuA\nx71NgSsVHuhdNCxP/h0s+6XYLAGGiB3McRJwNvACVsX6bKQjc64DvHuli8oVWJ580VGoexT+AmwL\nPA58S1VfjnhYznWYz+hd4VlbgyVEu/ma1jpoOhr2mKm6IOqxONdZXjDlojAJa2tQtCqhYaY1T3Ou\n5PmM3hWWpSZ+DGwZ9VCysAQYWAxdL53rDJ/Ru0I7AOtCWQp6AaOjHoRzneWB3hXaGKzVcCmoAQ6L\nehDOdZYHeldoo8itn3y7tsYS8Gux9J0xwL/CuPBGZcA3w72kc4Xngd4Vjq3PjwjzknOA1cAnwBbA\nT8K8uBmB9bRxrmR5oHeFtB3QlI8LdwfGA6+Hf+kkNm7nSpYHeldIQ7EzXkNXD9yDNbwP2Xps3M6V\nLK+MdYVUTUjr882OwJ7Ea4DNscY5IROKqxePcznzGb0rpEpCDvSzgeVYj+HrgX2BkI9yEiC0E6ic\ni4IHeldI64C8VOh1A44M/gz5EFgF0vand67Y+dKNK6QEeQr0CjyInfi9Q/iXToR7SecKywO9K6S3\nCfk5NxabxQswGLgN2DHMB7Dxvh3uJZ0rLO914wrH8uhXU1qbmwmgB/6L4kqYr9G7wrHmYG9EPYwc\nve5B3pU6D/Su0J4mT+v0eZAEnop6EM51lgd6V2gPYWnvpaAeeDjqQTjXWb5G7wrL+9E7V3A+o3eF\nZUFzKjZbLmb1wFQP8i4OfEbvCq8EzozFim23QnVZ1ANxrrN8Ru8Kz4LnzRRvIVICuMmDvIsLn9G7\naIjUAO8AW0U9lBQWA0NRLfblJeey4jN6Fw0LohMovll9ApjgQd7FiQd6Fx3V+cCtFE+wTwC3oPpM\n1ANxLky+dOOiJVIFPAHsQrSbs2uBF4HRqHq3ShcrHuhd9ERqse7Cw4gm2K8F3gL2QXV1BI/vXF75\n0o2LngXXfYB/UvhlnAQ2k/cg72LLA70rDhZk9wduoXDBPhE83mgP8i7OfOnGFR+RfbCzvuvIT0vj\nBHZGyYRgQ9i5WPMZvSs+FnyHYEVVawmvXUJ9cL2bgSEe5F1X4TN6V9ysXcLxwGSgF1BDbhOUJBbg\nV2I9dm71ilfX1Xigd6XBul4eAHwL+CYwAgvi67GTBAXrc6/Y8X9lwOtYP/mHgSe8QZnrqjzQu9Jk\ngX9bYCi2jl8FNGDr728D7/nJUM4ZD/TOORdzvhnrnHMx54HeOedizgO9c87FnAd655yLOQ/0zjkX\ncx7onXMu5jzQO+dczHmgd865mPNA75xzMeeB3jnnYs4DvXPOxZwHeuecizkP9M45F3Me6J1zLuY8\n0DvnXMx5oHfOuZjzQO+cczHngd4552LOA71zzsWcB3rnnIs5D/TOORdzHuidcy7mPNA751zMeaB3\nzrmY80DvnHMx54HeOedizgO9c87FnAd655yLOQ/0zjkXc/8fxO3/tONXi7QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5eafc6cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NB: Requires pip package networkx\n",
    "import networkx as nx\n",
    "np.random.seed(0)\n",
    "\n",
    "# create a networkx graph\n",
    "G = nx.MultiDiGraph()\n",
    "nodes = ['A','B', 'Aâˆ§Â¬B', 'Â¬Aâˆ§B', 'AâŠ•B']\n",
    "G.add_nodes_from(nodes)\n",
    "edges = {('A', 'Aâˆ§Â¬B'): '+', ('A', 'Â¬Aâˆ§B'): '-', \n",
    "         ('B', 'Aâˆ§Â¬B'): '-', ('B', 'Â¬Aâˆ§B'): '+', \n",
    "         ('Aâˆ§Â¬B', 'AâŠ•B'): '++', ('Â¬Aâˆ§B', 'AâŠ•B'): '++'}\n",
    "G.add_edges_from(edges.keys())\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_size=2000)\n",
    "nx.draw_networkx_labels(G, pos, dict(zip(nodes, nodes)))\n",
    "nx.draw_networkx_edges(G, pos)\n",
    "nx.draw_networkx_edge_labels(G, pos, edges)\n",
    "\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of linear threshold units trained using the Perceptron training algorithm)? \n",
    "\n",
    "A Logistic Regression model is easier to train, because its output is a smooth function of its parameters. Also, it directly encodes a conditional probability model, which may be easier to reason about in some cases.\n",
    "\n",
    "### How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?\n",
    "\n",
    "To make it easier to train, replace the LTU outputs with some kind of output which at least some of the time has a non-zero derivative with respect to the inputs. To encode a probability model, replace the outputs in the final layer with a softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Why was the logistic activation function a key ingredient in training the first MLPs?\n",
    "\n",
    "Non-trivial derivatives enabled effective backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Name three popular activation functions. Can you draw them?\n",
    "\n",
    "See the [Activation Functions section](http://localhost:8888/notebooks/10_introduction_to_artificial_neural_networks.ipynb#Activation-functions) above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Suppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function. \n",
    "\n",
    "#### What is the shape of the input matrix X? \n",
    "\n",
    "10x1\n",
    "\n",
    "#### What about the shape of the hidden layerâ€™s weight vector Wâ‚•, and the shape of its bias vector bâ‚•?\n",
    "\n",
    "50x10, 50x1\n",
    "\n",
    "#### What is the shape of the output layerâ€™s weight vector Wâ‚’, and its bias vector bâ‚’?\n",
    "\n",
    "3x50, 3x1\n",
    "\n",
    "#### What is the shape of the networkâ€™s output matrix Y?\n",
    "\n",
    "3x1\n",
    "\n",
    "#### Write the equation that computes the networkâ€™s output matrix Y as a function of X, Wâ‚•, bâ‚•, Wâ‚’ and bâ‚’.\n",
    "\n",
    "ReLU(Wâ‚’\\*ReLU(Wâ‚•\\*X+bâ‚•)+bâ‚’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. How many neurons do you need in the output layer if you want to classify email into spam or ham? \n",
    "\n",
    "1\n",
    "\n",
    "#### What activation function should you use in the output layer? \n",
    "\n",
    "Logistic\n",
    "\n",
    "#### If instead you want to tackle MNIST, how many neurons do you need in the output layer, using what activation function?\n",
    "\n",
    "10, softmax.\n",
    "\n",
    "#### Answer the same questions for getting your network to predict housing prices as in Chapter 2.\n",
    "\n",
    "Single float input for all fields except ocean proximity, which is a five-way one-hot encoded input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. What is backpropagation and how does it work? \n",
    "\n",
    "It is the chain rule, applied to numeric evaluation of the derivative of the network with respect to its parameters, at a fixed set of input value. An initial feedforward stage calculates the intermediate values for each output, given the inputs. Then, working backward through the network layers, the derivatives of the final output are computed by applying the chain rule.\n",
    "\n",
    "#### What is the difference between backpropagation and reverse-mode autodiff?\n",
    "\n",
    "They are the same algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Can you list all the hyperparameters you can tweak in an MLP? \n",
    "\n",
    "All optimization parameters (learning rate, momentum, etc.), number of layers, number of outputs in each hidden layer, activation function for each output.\n",
    "\n",
    "#### If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?\n",
    "\n",
    "- Implicit regularization through noisy optimization procedures like stochastic gradient descent. E.g., increase the learning rate.\n",
    "\n",
    "- Simplify the parameter space by reducing the number of layers / number of hidden outputs.\n",
    "\n",
    "- Noise on inputs / outputs. E.g., a stochastic activation function, dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Train a deep MLP on the MNIST dataset and see if you can get over 98% precision. Just like in the last exercise of Chapter 9, try adding all the bells and whistles (i.e., save checkpoints, restore the last checkpoint in case of an interruption, add summaries, plot learning curves using TensorBoard, and so on).\n",
    "\n",
    "In this context, accuracy and precision (at least the average precision over the digit classes, weighted by their frequency) are the same value. It suffices to double the number of hidden outputs in each layer of the model defined in [Using plain TensorFlow](http://localhost:8888/notebooks/10_introduction_to_artificial_neural_networks.ipynb#Using-plain-TensorFlow) above, and let it run a bit longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "MLPTensors = namedtuple(\n",
    "    'MLP', 'X y hidden logits loss training accuracy init saver summary test_writer train_writer')\n",
    "\n",
    "def MLP(n_inputs, n_hidden_outputs, n_outputs, learning_rate, name='MLP'):\n",
    "    \"\"\"Return the tensors for an MLP with the given architecture and learning rate.\"\"\"\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "    y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "    with tf.name_scope(name + \"/dnn\"):\n",
    "        hidden = []\n",
    "        for i, n_hidden in enumerate(n_hidden_outputs):\n",
    "            hidden.append(neuron_layer(X, n_hidden, \"hidden1\", activation=\"relu\"))\n",
    "        logits = neuron_layer(hidden[-1], n_outputs, \"output\")\n",
    "\n",
    "    with tf.name_scope(name + \"/loss\"):\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "    with tf.name_scope(name + \"/train\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "    with tf.name_scope(name + \"/eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        tf.summary.scalar('accuracy', accuracy)        \n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    summary = tf.summary.merge_all()\n",
    "    test_writer = tf.summary.FileWriter('/tmp/mlp/test', tf.get_default_graph())\n",
    "    train_writer = tf.summary.FileWriter('/tmp/mlp/train', tf.get_default_graph())\n",
    "    return MLPTensors(**{'X': X, 'y': y, 'hidden': hidden, 'logits': logits,\n",
    "                         'loss': loss, 'training': training_op, 'accuracy': accuracy,\n",
    "                         'init': init, 'saver': saver, 'summary': summary,\n",
    "                         'test_writer': test_writer, 'train_writer': train_writer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "mlp = MLP(28*28, [1000, 600], 10, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/mlp.chk-3\n",
      "0 Train accuracy: 0.92 Test accuracy: 0.9261 Train loss: 0.260217 Test loss: 0.270398\n",
      "1 Train accuracy: 0.98 Test accuracy: 0.9308 Train loss: 0.129181 Test loss: 0.251152\n",
      "2 Train accuracy: 0.92 Test accuracy: 0.9335 Train loss: 0.194827 Test loss: 0.239045\n",
      "3 Train accuracy: 0.96 Test accuracy: 0.9367 Train loss: 0.16071 Test loss: 0.228143\n",
      "4 Train accuracy: 0.98 Test accuracy: 0.9388 Train loss: 0.139626 Test loss: 0.219848\n",
      "5 Train accuracy: 0.94 Test accuracy: 0.9407 Train loss: 0.175978 Test loss: 0.207654\n",
      "6 Train accuracy: 0.94 Test accuracy: 0.9434 Train loss: 0.219057 Test loss: 0.199423\n",
      "7 Train accuracy: 0.92 Test accuracy: 0.9456 Train loss: 0.32286 Test loss: 0.190682\n",
      "8 Train accuracy: 0.94 Test accuracy: 0.9478 Train loss: 0.208884 Test loss: 0.184447\n",
      "9 Train accuracy: 0.98 Test accuracy: 0.9495 Train loss: 0.111148 Test loss: 0.177446\n",
      "10 Train accuracy: 0.98 Test accuracy: 0.952 Train loss: 0.102998 Test loss: 0.170991\n",
      "11 Train accuracy: 0.96 Test accuracy: 0.9522 Train loss: 0.256781 Test loss: 0.166713\n",
      "12 Train accuracy: 1.0 Test accuracy: 0.9542 Train loss: 0.0830321 Test loss: 0.160896\n",
      "13 Train accuracy: 0.94 Test accuracy: 0.9556 Train loss: 0.253659 Test loss: 0.156261\n",
      "14 Train accuracy: 0.92 Test accuracy: 0.9567 Train loss: 0.345126 Test loss: 0.150675\n",
      "15 Train accuracy: 0.98 Test accuracy: 0.9582 Train loss: 0.129011 Test loss: 0.146696\n",
      "16 Train accuracy: 0.92 Test accuracy: 0.9586 Train loss: 0.222427 Test loss: 0.143549\n",
      "17 Train accuracy: 0.98 Test accuracy: 0.9592 Train loss: 0.063193 Test loss: 0.138987\n",
      "18 Train accuracy: 0.96 Test accuracy: 0.9608 Train loss: 0.137913 Test loss: 0.135461\n",
      "19 Train accuracy: 0.98 Test accuracy: 0.9623 Train loss: 0.0822397 Test loss: 0.131981\n",
      "20 Train accuracy: 0.98 Test accuracy: 0.9633 Train loss: 0.0956058 Test loss: 0.128603\n",
      "21 Train accuracy: 0.94 Test accuracy: 0.9637 Train loss: 0.13948 Test loss: 0.126427\n",
      "22 Train accuracy: 1.0 Test accuracy: 0.9636 Train loss: 0.0635542 Test loss: 0.124074\n",
      "23 Train accuracy: 0.96 Test accuracy: 0.9642 Train loss: 0.140779 Test loss: 0.120613\n",
      "24 Train accuracy: 0.96 Test accuracy: 0.9651 Train loss: 0.115491 Test loss: 0.117855\n",
      "25 Train accuracy: 0.98 Test accuracy: 0.9652 Train loss: 0.0574127 Test loss: 0.115997\n",
      "26 Train accuracy: 1.0 Test accuracy: 0.966 Train loss: 0.0286686 Test loss: 0.113814\n",
      "27 Train accuracy: 0.98 Test accuracy: 0.9668 Train loss: 0.065181 Test loss: 0.111073\n",
      "28 Train accuracy: 0.98 Test accuracy: 0.9676 Train loss: 0.0599562 Test loss: 0.109097\n",
      "29 Train accuracy: 0.94 Test accuracy: 0.9679 Train loss: 0.143325 Test loss: 0.108162\n",
      "30 Train accuracy: 0.94 Test accuracy: 0.9677 Train loss: 0.092329 Test loss: 0.106052\n",
      "31 Train accuracy: 0.98 Test accuracy: 0.9688 Train loss: 0.050069 Test loss: 0.104794\n",
      "32 Train accuracy: 1.0 Test accuracy: 0.9691 Train loss: 0.0599399 Test loss: 0.102395\n",
      "33 Train accuracy: 1.0 Test accuracy: 0.9699 Train loss: 0.0522462 Test loss: 0.101231\n",
      "34 Train accuracy: 1.0 Test accuracy: 0.9704 Train loss: 0.0301412 Test loss: 0.100218\n",
      "35 Train accuracy: 0.96 Test accuracy: 0.9703 Train loss: 0.236106 Test loss: 0.0988347\n",
      "36 Train accuracy: 1.0 Test accuracy: 0.9701 Train loss: 0.0452591 Test loss: 0.0975468\n",
      "37 Train accuracy: 0.98 Test accuracy: 0.9714 Train loss: 0.0867764 Test loss: 0.0959614\n",
      "38 Train accuracy: 1.0 Test accuracy: 0.9711 Train loss: 0.0315485 Test loss: 0.0954251\n",
      "39 Train accuracy: 1.0 Test accuracy: 0.9715 Train loss: 0.027761 Test loss: 0.0940362\n",
      "40 Train accuracy: 1.0 Test accuracy: 0.9731 Train loss: 0.0256655 Test loss: 0.0932718\n",
      "41 Train accuracy: 0.96 Test accuracy: 0.9731 Train loss: 0.0829538 Test loss: 0.0918693\n",
      "42 Train accuracy: 0.96 Test accuracy: 0.9736 Train loss: 0.0873074 Test loss: 0.0906246\n",
      "43 Train accuracy: 0.98 Test accuracy: 0.9741 Train loss: 0.091011 Test loss: 0.0893484\n",
      "44 Train accuracy: 1.0 Test accuracy: 0.9742 Train loss: 0.0551287 Test loss: 0.0884921\n",
      "45 Train accuracy: 1.0 Test accuracy: 0.9746 Train loss: 0.0120819 Test loss: 0.0876444\n",
      "46 Train accuracy: 1.0 Test accuracy: 0.9746 Train loss: 0.0327761 Test loss: 0.0872657\n",
      "47 Train accuracy: 1.0 Test accuracy: 0.9748 Train loss: 0.0448616 Test loss: 0.0864097\n",
      "48 Train accuracy: 1.0 Test accuracy: 0.9752 Train loss: 0.0213792 Test loss: 0.0851642\n",
      "49 Train accuracy: 1.0 Test accuracy: 0.9753 Train loss: 0.0342914 Test loss: 0.0846671\n",
      "50 Train accuracy: 0.96 Test accuracy: 0.9754 Train loss: 0.18662 Test loss: 0.0839692\n",
      "51 Train accuracy: 1.0 Test accuracy: 0.9754 Train loss: 0.042245 Test loss: 0.0832217\n"
     ]
    }
   ],
   "source": [
    "import glob, re\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    mlp.init.run()\n",
    "    \n",
    "    # Check whether there's a checkpoint to restore from\n",
    "    chkpath = '/tmp/mlp.chk'\n",
    "    checkpoints = glob.glob(chkpath + '-*')\n",
    "    if checkpoints:  # Restore from last checkpoint\n",
    "        # Remove the suffix from the last checkpoint\n",
    "        last_chk = re.sub(r'\\.[^.]+$', '', max(checkpoints))\n",
    "        mlp.saver.restore(sess, last_chk)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            train_data = {mlp.X: X_batch, mlp.y: y_batch}\n",
    "            _, closs, acc_train = sess.run(\n",
    "                [mlp.training, mlp.loss, mlp.accuracy], \n",
    "                feed_dict=train_data)\n",
    "        summary = mlp.summary.eval(feed_dict=train_data)\n",
    "        mlp.train_writer.add_summary(summary, epoch)\n",
    "        mlp.train_writer.flush()\n",
    "        test_data = {mlp.X: mnist.test.images, mlp.y: mnist.test.labels}\n",
    "        loss_test, acc_test, summary = sess.run(\n",
    "            [mlp.loss, mlp.accuracy, mlp.summary], \n",
    "            feed_dict=test_data)\n",
    "        mlp.test_writer.add_summary(mlp.summary.eval(feed_dict=test_data), epoch)\n",
    "        mlp.test_writer.flush()\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test,\n",
    "              \"Train loss:\", closs, \"Test loss:\", loss_test)\n",
    "        mlp.saver.save(sess, chkpath, global_step=epoch)\n",
    "        if acc_test >= .98:\n",
    "            break\n",
    "\n",
    "    save_path = mlp.saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.27843022563&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0357142873108\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;MLP/dnn/hidden1/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;MLP/dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;MLP/dnn/hidden1/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MLP/dnn/hidden1/truncated_normal/mul&quot;\\n  input: &quot;MLP/dnn/hidden1/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/hidden1/weights&quot;\\n  input: &quot;MLP/dnn/hidden1/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/dnn/hidden1/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/hidden1/biases&quot;\\n  input: &quot;MLP/dnn/hidden1/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/dnn/hidden1/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;MLP/dnn/hidden1/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MLP/dnn/hidden1/MatMul&quot;\\n  input: &quot;MLP/dnn/hidden1/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;MLP/dnn/hidden1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000\\\\310\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0357142873108\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;MLP/dnn/hidden1_1/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;MLP/dnn/hidden1_1/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;MLP/dnn/hidden1_1/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MLP/dnn/hidden1_1/truncated_normal/mul&quot;\\n  input: &quot;MLP/dnn/hidden1_1/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 200\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/hidden1_1/weights&quot;\\n  input: &quot;MLP/dnn/hidden1_1/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1_1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/dnn/hidden1_1/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1_1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 200\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 200\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/hidden1_1/biases&quot;\\n  input: &quot;MLP/dnn/hidden1_1/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1_1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/dnn/hidden1_1/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1_1/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;MLP/dnn/hidden1_1/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MLP/dnn/hidden1_1/MatMul&quot;\\n  input: &quot;MLP/dnn/hidden1_1/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/hidden1_1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;MLP/dnn/hidden1_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\310\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0707106813788\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;MLP/dnn/output/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;MLP/dnn/output/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;MLP/dnn/output/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MLP/dnn/output/truncated_normal/mul&quot;\\n  input: &quot;MLP/dnn/output/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 200\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/output/weights&quot;\\n  input: &quot;MLP/dnn/output/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/output/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/dnn/output/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/output/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/output/biases&quot;\\n  input: &quot;MLP/dnn/output/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/output/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/dnn/output/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/output/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;MLP/dnn/hidden1_1/Relu&quot;\\n  input: &quot;MLP/dnn/output/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/output/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MLP/dnn/output/MatMul&quot;\\n  input: &quot;MLP/dnn/output/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/logits/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;MLP/dnn/logits&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/dnn/logits&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;MLP/dnn/logits/tags&quot;\\n  input: &quot;MLP/dnn/output/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;MLP/dnn/output/add&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;MLP/loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/loss/loss_1/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;MLP/loss/loss_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/loss/loss_1&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;MLP/loss/loss_1/tags&quot;\\n  input: &quot;MLP/loss/loss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;MLP/train/gradients/Shape&quot;\\n  input: &quot;MLP/train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;MLP/train/gradients/Fill&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Reshape&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Shape_1&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Shape_2&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Prod_1&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Prod&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Tile&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/loss_grad/truediv&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;MLP/dnn/output/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Shape&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Sum&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;MLP/train/gradients/MLP/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Sum_1&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/output/add_grad/Reshape&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/output/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Reshape&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/output/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/train/gradients/MLP/dnn/output/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/Reshape_1&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/output/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/train/gradients/MLP/dnn/output/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/tuple/control_dependency&quot;\\n  input: &quot;MLP/dnn/output/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;MLP/dnn/hidden1_1/Relu&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/output/MatMul_grad/MatMul&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/output/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/MatMul_grad/MatMul&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/output/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/train/gradients/MLP/dnn/output/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/output/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/output/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/train/gradients/MLP/dnn/output/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;MLP/dnn/hidden1_1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;MLP/dnn/hidden1_1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 200\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Shape&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/Relu_grad/ReluGrad&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Sum&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/Relu_grad/ReluGrad&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Sum_1&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Reshape&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Reshape&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Reshape_1&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;MLP/dnn/hidden1_1/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.00999999977648\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/GradientDescent/update_MLP/dnn/hidden1_1/weights/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;MLP/dnn/hidden1_1/weights&quot;\\n  input: &quot;MLP/train/GradientDescent/learning_rate&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1_1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/GradientDescent/update_MLP/dnn/hidden1_1/biases/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;MLP/dnn/hidden1_1/biases&quot;\\n  input: &quot;MLP/train/GradientDescent/learning_rate&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/hidden1_1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1_1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/GradientDescent/update_MLP/dnn/output/weights/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;MLP/dnn/output/weights&quot;\\n  input: &quot;MLP/train/GradientDescent/learning_rate&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/output/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/GradientDescent/update_MLP/dnn/output/biases/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;MLP/dnn/output/biases&quot;\\n  input: &quot;MLP/train/GradientDescent/learning_rate&quot;\\n  input: &quot;MLP/train/gradients/MLP/dnn/output/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/output/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^MLP/train/GradientDescent/update_MLP/dnn/hidden1_1/weights/ApplyGradientDescent&quot;\\n  input: &quot;^MLP/train/GradientDescent/update_MLP/dnn/hidden1_1/biases/ApplyGradientDescent&quot;\\n  input: &quot;^MLP/train/GradientDescent/update_MLP/dnn/output/weights/ApplyGradientDescent&quot;\\n  input: &quot;^MLP/train/GradientDescent/update_MLP/dnn/output/biases/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;MLP/eval/InTopK&quot;\\n  op: &quot;InTopK&quot;\\n  input: &quot;MLP/dnn/output/add&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;k&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;MLP/eval/InTopK&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;MLP/eval/Cast&quot;\\n  input: &quot;MLP/eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/eval/accuracy/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;MLP/eval/accuracy&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MLP/eval/accuracy&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;MLP/eval/accuracy/tags&quot;\\n  input: &quot;MLP/eval/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^MLP/dnn/hidden1/weights/Assign&quot;\\n  input: &quot;^MLP/dnn/hidden1/biases/Assign&quot;\\n  input: &quot;^MLP/dnn/hidden1_1/weights/Assign&quot;\\n  input: &quot;^MLP/dnn/hidden1_1/biases/Assign&quot;\\n  input: &quot;^MLP/dnn/output/weights/Assign&quot;\\n  input: &quot;^MLP/dnn/output/biases/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;MLP/dnn/hidden1/biases&quot;\\n        string_val: &quot;MLP/dnn/hidden1/weights&quot;\\n        string_val: &quot;MLP/dnn/hidden1_1/biases&quot;\\n        string_val: &quot;MLP/dnn/hidden1_1/weights&quot;\\n        string_val: &quot;MLP/dnn/output/biases&quot;\\n        string_val: &quot;MLP/dnn/output/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;MLP/dnn/hidden1/biases&quot;\\n  input: &quot;MLP/dnn/hidden1/weights&quot;\\n  input: &quot;MLP/dnn/hidden1_1/biases&quot;\\n  input: &quot;MLP/dnn/hidden1_1/weights&quot;\\n  input: &quot;MLP/dnn/output/biases&quot;\\n  input: &quot;MLP/dnn/output/weights&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;MLP/dnn/hidden1/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/hidden1/biases&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;MLP/dnn/hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/hidden1/weights&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;MLP/dnn/hidden1_1/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/hidden1_1/biases&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1_1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;MLP/dnn/hidden1_1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/hidden1_1/weights&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/hidden1_1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;MLP/dnn/output/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/output/biases&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/output/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;MLP/dnn/output/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;MLP/dnn/output/weights&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@MLP/dnn/output/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\nnode {\\n  name: &quot;Merge/MergeSummary&quot;\\n  op: &quot;MergeSummary&quot;\\n  input: &quot;MLP/dnn/logits&quot;\\n  input: &quot;MLP/loss/loss_1&quot;\\n  input: &quot;MLP/eval/accuracy&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.27843022563&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "    \n",
    "show_graph(tf.get_default_graph())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
